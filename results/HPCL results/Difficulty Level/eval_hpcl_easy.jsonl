{"predict": "(14, OpenCL, retVal = clReleaseMemObject(image);)", "label": "(14, OpenCL, retVal = clReleaseMemObject(image);)"}
{"predict": "(19, CUDA, CHECK(cudaMalloc((void**) &anchorsDev, 4 * params.anchorsRatioCount * params.anchorsScaleCount * sizeof(float)));)", "label": "(17, CUDA, CHECK(cudaMalloc((void**) &anchorsDev, 4 * params.anchorsRatioCount * params.anchorsScaleCount * sizeof(float)));)"}
{"predict": "(3, CUDA, extern __shared__ float entire_buffer[];)", "label": "(3, CUDA, extern __shared__ float entire_buffer[];)"}
{"predict": "(24, CUDA, cudaFree(res_dev);); (17, CUDA, cudaMalloc(&res_dev, sizeof(float));); (19, CUDA, cudaMemcpy(&res_host, res_dev, sizeof(float), cudaMemcpyDeviceToHost);)", "label": "(24, CUDA, cudaFree(res_dev);); (17, CUDA, cudaMalloc(&res_dev, sizeof(float));); (19, CUDA, cudaMemcpy(&res_host, res_dev, sizeof(float), cudaMemcpyDeviceToHost);)"}
{"predict": "(7, OpenCL, void *mappedPtr = clEnqueueMapBuffer(cmdQ.get(), buffer.get(), CL_FALSE, CL_MAP_READ, offset, size, 0, nullptr, nullptr, nullptr);); (13, OpenCL, retVal = clEnqueueUnmapMemObject(cmdQ.get(), buffer.get(), mappedPtr, 0, nullptr, nullptr);)", "label": "(14, OpenCL, retVal = clEnqueueUnmapMemObject(cmdQ.get(), buffer.get(), mappedPtr, 0, nullptr, nullptr);); (6, OpenCL, void *mappedPtr = clEnqueueMapBuffer(cmdQ.get(), buffer.get(), CL_FALSE, CL_MAP_WRITE, offset, size, 0, nullptr, nullptr, nullptr);)"}
{"predict": "(4, CUDA, cudaError_t err = cudaFree(handle->workspace);); (8, CUDA, err = cudaFree(handle->deterministic_workspace);)", "label": "(4, CUDA, auto err = cudaFree(handle->deviceWs);); (8, CUDA, err = cudaEventDestroy(handle->wsMutex);)"}
{"predict": "(18, MPI, MPI_Comm_rank(MPI_COMM_SELF, &rank);)", "label": "(18, MPI, MPI_Comm_rank(MPI_COMM_WORLD, &rank);)"}
{"predict": "(51, OpenCL, clReleaseEvent(event);)", "label": "(50, OpenCL, clReleaseEvent(event);)"}
{"predict": "(3, CUDA, extern __shared__ float shared[];)", "label": "(3, CUDA, extern __shared__ float shared[];)"}
{"predict": "(4, OpenMP, #pragma omp parallel for)", "label": "(4, OpenMP, #pragma omp parallel for)"}
{"predict": "(1, CUDA, __shared__ float cache[threadsPerBlock];)", "label": "(1, CUDA, __shared__ float cache[threadsPerBlock];)"}
{"predict": "(2, OpenMP, #pragma omp for collapse(2) schedule(runtime)); (8, OpenMP, #pragma omp parallel for schedule(runtime))", "label": "(3, OpenMP, #pragma omp for collapse(2) schedule(runtime))"}
{"predict": "(25, MPI, MPI_Bcast(fparams, 1, MPI_FLOAT, 0, MPI_COMM_WORLD);); (6, MPI, MPI_Bcast(iparams, num_int_params, MPI_INT, 0, MPI_COMM_WORLD);)", "label": "(23, MPI, MPI_Bcast(&fparams[0], 1, MPI_FLOAT, 0, MPI_COMM_WORLD);); (6, MPI, MPI_Bcast(&iparams[0], num_int_params, MPI_INT, 0, MPI_COMM_WORLD);)"}
{"predict": "(11, MPI, ::dray::dray::mpi_comm(MPI_Comm_c2f(comm));)", "label": "(11, MPI, ::dray::dray::mpi_comm(MPI_Comm_c2f(comm));)"}
{"predict": "(15, CUDA, __shared__ typename BlockReduceT::TempStorage temp_storage;)", "label": "(15, CUDA, __shared__ typename BlockReduceT::TempStorage temp_storage;)"}
{"predict": "(14, OpenMP, return comp_by_value(lv, rv, by_number, ascendingly, casesensitively);)", "label": "(14, OpenMP, return comp_raw(lv, rv, by_number, ascendingly, casesensitively);)"}
{"predict": "(11, MPI, rc = MPI_Comm_connect(port_name, MPI_INFO_NULL, 0, MPI_COMM_WORLD, &errs);); (14, MPI, MPI_Error_class(rc, &errclass);); (8, MPI, MPI_Comm_set_errhandler(MPI_COMM_WORLD, MPI_ERRORS_RETURN);)", "label": "(12, MPI, rc = MPI_Unpublish_name(serv_name, MPI_INFO_NULL, port_name);); (12, MPI, MPI_Error_class(rc, &errclass);); (8, MPI, MPI_Comm_set_errhandler(MPI_COMM_WORLD, MPI_ERRORS_RETURN);)"}
{"predict": "(8, MPI, MPI_Comm_rank(comm, &comm_rank);); (9, MPI, MPI_Comm_size(comm, &comm_size);)", "label": "(8, MPI, MPI_Comm_rank(comm, &comm_rank);); (9, MPI, MPI_Comm_size(comm, &comm_size);)"}
{"predict": "(4, OpenMP, #pragma omp parallel sections); (5, OpenMP, #pragma omp section)", "label": "(5, OpenMP, #pragma omp sections); (3, OpenMP, #pragma omp parallel); (5, OpenMP, #pragma omp section)"}
{"predict": "(42, OpenMP, #pragma omp target); (42, OpenMP, #pragma omp target firstprivate(val))", "label": "(42, OpenMP, #pragma omp target); (42, OpenMP, #pragma omp target firstprivate(val))"}
{"predict": "(11, CUDA, cuda_safe_call(cudaGetDeviceCount(&ndevs));)", "label": "(24, CUDA, cuda_safe_call(cudaStreamSynchronize(stream));); (10, CUDA, cuda_safe_call(cudaGetDeviceCount(&ndevs));)"}
{"predict": "(26, OpenCL, status = clReleaseEvent(event);); (13, OpenCL, auto status = clWaitForEvents(1, &event);)", "label": "(26, OpenCL, status = clReleaseEvent(event);); (13, OpenCL, auto status = clWaitForEvents(1, &event);)"}
{"predict": "(25, OpenCL, clReleaseEvent(retEvent);); (25, OpenCL, clReleaseEvent(retEvent2);)", "label": "(25, OpenCL, clReleaseEvent(retEvent2);); (25, OpenCL, clReleaseEvent(retEvent);)"}
{"predict": "(18, MPI, MPI_Comm_free(&comm);); (5, MPI, MPI_Comm_rank(comm, &rank);)", "label": "(3, MPI, MPI_Barrier(MPI_COMM_WORLD);); (5, MPI, MPI_Comm_rank(MPI_COMM_WORLD, &rank);); (16, MPI, MPI_Comm_free(&comm);)"}
{"predict": "(9, MPI, t = MPI_Wtime();); (11, MPI, t = MPI_Wtime() - t;)", "label": "(9, MPI, t = MPI_Wtime();); (11, MPI, t = MPI_Wtime() - t;)"}
{"predict": "(10, OpenMP, #pragma omp target teams distribute parallel for reduction(min : minval))", "label": "(10, OpenMP, #pragma omp target teams distribute parallel for map(tofrom:minval) reduction(min:minval))"}
{"predict": "(1, TBB, using namespace tbb::flow;)", "label": "(1, TBB, using namespace tbb::flow;)"}
{"predict": "(24, CUDA, cuda_safe_call(cudaStreamSynchronize(stream));)", "label": "(18, CUDA, cuda_safe_call(cudaGetLastError());)"}
{"predict": "(18, CUDA, CUDA_CHECK(cudaGetLastError());)", "label": "(18, CUDA, CUDA_CHECK(cudaGetLastError());)"}
{"predict": "(8, CUDA, CUDA_CHECK(cudaMemGetInfo(&freeCUDAMem, &totalCUDAMem));)", "label": "(5, CUDA, cudaSetDevice(0);); (8, CUDA, cudaMemGetInfo(&freeCUDAMem, &totalCUDAMem);)"}
{"predict": "(22, CUDA, cudaFree(res_dev);); (15, CUDA, cudaMemcpy(&res_host, res_dev, sizeof(bool), cudaMemcpyDeviceToHost);); (11, CUDA, cudaMalloc(&res_dev, sizeof(bool));)", "label": "(22, CUDA, cudaFree(res_dev);); (15, CUDA, cudaMemcpy(&res_host, res_dev, sizeof(bool), cudaMemcpyDeviceToHost);); (11, CUDA, cudaMalloc(&res_dev, sizeof(bool));)"}
{"predict": "(4, OpenMP, #pragma omp target teams distribute simd firstprivate(g, g1, sivar))", "label": "(4, OpenMP, #pragma omp target teams distribute simd firstprivate(g, g1, sivar))"}
{"predict": "(7, CUDA, cudaDeviceSynchronize();); (14, CUDA, cudaGraphicsUnmapResources(1, &cuda_pbo_resource, 0);); (0, CUDA, cudaGraphicsMapResources(1, &cuda_pbo_resource, 0);)", "label": "(2, CUDA, cudaGraphicsMapResources(1, &cuda_pbo_resource, 0);); (7, CUDA, cudaGraphicsUnmapResources(1, &cuda_pbo_resource, 0);)"}
{"predict": "(3, OpenMP, #pragma omp target map(tofrom: threadCount)); (4, OpenMP, #pragma omp metadirective)", "label": "(3, OpenMP, #pragma omp target map(tofrom: threadCount)); (4, OpenMP, #pragma omp metadirective)"}
{"predict": "(33, OpenCL, clReleaseEvent(retEvent);)", "label": "(33, OpenCL, clReleaseEvent(retEvent);)"}
{"predict": "(16, CUDA, ensemble = new flamegpu::CUDAEnsemble(model, 2, argv);); (6, CUDA, ensemble = new flameGPU::CUDAEnsemble(model);)", "label": "(16, CUDA, EXPECT_NO_THROW(ensemble = new flamegpu::CUDAEnsemble(model, sizeof(argv) / sizeof(char*), argv));); (6, CUDA, EXPECT_NO_THROW(ensemble = new flamegpu::CUDAEnsemble(model, 0, nullptr));)"}
{"predict": "(20, MPI, *ierr = MPI_Info_get_valuelen( (MPI_Info)(*v1), p2, v3, &l4, (void *)0 );)", "label": "(19, MPI, *ierr = MPI_Info_get_valuelen( (MPI_Info)(*v1), p2, v3, &l4 );)"}
{"predict": "(5, CUDA, cudaFree(0);)", "label": "(3, CUDA, cudaFree( 0 );)"}
{"predict": "(2, CUDA, LogDebug(LOG_PY_UTILS \"PyCudaMemory_New()\\n\");)", "label": "(2, CUDA, LogDebug(LOG_PY_UTILS \"PyCudaMemory_New()\\n\");)"}
{"predict": "(7, SYCL, EasyCL *cl = EasyCL::createForFirstGpuOtherwiseCpu();)", "label": "(7, SYCL, EasyCL *cl = EasyCL::createForFirstGpuOtherwiseCpu();)"}
{"predict": "(6, OpenMP, #pragma omp for); (3, OpenMP, #pragma omp target map(obj))", "label": "(6, OpenMP, #pragma omp for reduction(+:count) lastprivate(obj)); (9, OpenMP, #pragma omp cancel for); (2, OpenMP, #pragma omp parallel private(i) num_threads(1))"}
{"predict": "(18, CUDA, cudaFree(res_dev);); (8, CUDA, cudaMalloc(&res_dev, sizeof(float));); (10, CUDA, cudaMemcpy(&res_host, res_dev, sizeof(float), cudaMemcpyDeviceToHost);)", "label": "(18, CUDA, cudaFree(res_dev);); (8, CUDA, cudaMalloc(&res_dev, sizeof(float));); (10, CUDA, cudaMemcpy(&res_host, res_dev, sizeof(float), cudaMemcpyDeviceToHost);)"}
{"predict": "(6, CUDA, cudaMalloc(&raw_ptr, N * sizeof(int));); (19, CUDA, cudaFree(raw_ptr);); (7, CUDA, thrust::device_ptr<int> dev_ptr(raw_ptr);); (9, CUDA, thrust::fill(dev_ptr, dev_ptr + N, 0);)", "label": "(6, CUDA, cudaMalloc((void**) &raw_ptr, N * sizeof(int));); (11, CUDA, thrust::fill(dev_ptr, dev_ptr + N, (int) 0);); (7, CUDA, thrust::device_ptr<int> dev_ptr = thrust::device_pointer_cast(raw_ptr);); (15, CUDA, cudaFree(raw_ptr);)"}
{"predict": "(28, MPI, Mpi.SignalProgress();)", "label": "(29, MPI, Mpi.SignalProgress();)"}
{"predict": "(12, OpenMP, #pragma omp parallel for)", "label": "(13, OpenMP, #pragma omp parallel for)"}
{"predict": "(3, CUDA, __shared__ float local[threads];)", "label": "(3, CUDA, __shared__ float local[threads];)"}
{"predict": "(129, CUDA, cudaMemcpy(z_cu, z, shape.Z_len * sizeof(DT), cudaMemcpyHostToDevice);); (211, CUDA, cudaFree(x_cu);); (122, CUDA, cudaMalloc(&x_cu, shape.X_len * sizeof(ST));); (125, CUDA, cudaMemcpy(y_cu, y, shape.Y_len * sizeof(ST), cudaMemcpyHostToDevice);); (123, CUDA, cudaMemcpy(x_cu, x, shape.X_len * sizeof(ST), cudaMemcpyHostToDevice);); (208, CUDA, cudaFree(y_cu);); (120, CUDA, cudaMalloc(&z_cu, shape.Z_len * sizeof(DT));); (118, CUDA, cudaMalloc(&y_cu, shape.Y_len * sizeof(ST));); (128, CUDA, CHECK_HIEDNN(hiednnCreateCudaHandle(&handle));); (210, CUDA, CHECK_HIEDNN(hiednnDestroyCudaHandle(handle));); (204, CUDA, cudaFree(z_cu);)", "label": "(129, CUDA, cudaMemcpy(z_cu, z, shape.Z_len * sizeof(DT), cudaMemcpyHostToDevice);); (221, CUDA, cudaFree(x_cu);); (122, CUDA, cudaMalloc(&x_cu, shape.X_len * sizeof(ST));); (125, CUDA, cudaMemcpy(y_cu, y, shape.Y_len * sizeof(ST), cudaMemcpyHostToDevice);); (123, CUDA, cudaMemcpy(x_cu, x, shape.X_len * sizeof(ST), cudaMemcpyHostToDevice);); (218, CUDA, cudaFree(y_cu);); (120, CUDA, cudaMalloc(&z_cu, shape.Z_len * sizeof(DT));); (118, CUDA, cudaMalloc(&y_cu, shape.Y_len * sizeof(ST));); (128, CUDA, CHECK_HIEDNN(hiednnCreateCudaHandle(&handle));); (220, CUDA, CHECK_HIEDNN(hiednnDestroyCudaHandle(handle));); (214, CUDA, cudaFree(z_cu);)"}
{"predict": "(4, CUDA, extern __shared__ float entire_buffer[];)", "label": "(6, CUDA, extern __shared__ float entire_buffer[];)"}
{"predict": "(16, OpenCL, clCreateCommandQueueWithProperties_StubWithCallback(clCreateCommandQueueWithProperties_testCommandQueueFromSpecifiedContext);); (29, OpenCL, clReleaseContext_ExpectAndReturn(expected_context, CL_SUCCESS);); (38, OpenCL, clReleaseMemObject_ExpectAndReturn(expected_device, CL_SUCCESS);); (29, OpenCL, clReleaseCommandQueue_ExpectAndReturn(expected, CL_SUCCESS);)", "label": "(18, OpenCL, clCreateCommandQueueWithProperties_StubWithCallback(clCreateCommandQueueWithProperties_testCommandQueueFromSpecifiedContext);)"}
{"predict": "(25, OpenCL, clReleaseEvent(outEvent);)", "label": "(25, OpenCL, clReleaseEvent(outEvent);)"}
{"predict": "(8, OpenCL, cl_status = clGetPlatformInfo(id, param_name, param_size, some_info, NULL);)", "label": "(8, OpenCL, cl_status = clGetPlatformInfo(id, param_name, param_size, some_info, NULL);)"}
{"predict": "(13, CUDA, CUDASimulation cudaSimulation(model);)", "label": "(13, CUDA, CUDASimulation cudaSimulation(model);)"}
{"predict": "(13, TBB, tbb::cache_aligned_allocator<dtcmp_op_handle_t>().deallocate(c, 1);)", "label": "(9, MPI, MPI_Type_free(&(c->key));)"}
{"predict": "(2, OpenMP, #pragma omp dispatch)", "label": "(2, OpenMP, #pragma omp dispatch)"}
{"predict": "(16, OpenCL, status = clSetKernelArg(global_check, 0, sizeof(cl_mem), &buffer);)", "label": "(16, OpenCL, status = clSetKernelArg(global_check, 0, sizeof(cl_mem), &buffer);)"}
{"predict": "(7, CUDA, err = cudaMemcpyAsync( dst, src, sz, type, 0 );); (13, CUDA, cudaGetLastError();)", "label": "(7, CUDA, err = cudaMemcpy( dst, src, sz, type );); (10, CUDA, ss << cudaGetErrorString(err) << endl;)"}
{"predict": "(1, TBB, typedef tbb::atomic<ScopedColor> TestAtomic;)", "label": "(10, TBB, __TBB_STATIC_ASSERT( !HasImplicitConversionToInt< tbb::atomic<ScopedColor1> >::value, \"The implicit conversion is not expected.\" );); (12, TBB, __TBB_STATIC_ASSERT( sizeof(tbb::atomic<ScopedColor2>) == sizeof(ScopedColor2), \"tbb::atomic instantiated with scoped enum should have the same size as scoped enum.\" );); (10, TBB, __TBB_STATIC_ASSERT( sizeof(tbb::atomic<ScopedColor1>) == sizeof(ScopedColor1), \"tbb::atomic instantiated with scoped enum should have the same size as scoped enum.\" );)"}
{"predict": "(11, OpenMP, #pragma omp parallel for); (0, OpenMP, #pragma omp task)", "label": "(17, OpenMP, #pragma omp taskwait); (0, OpenMP, #pragma omp task); (2, OpenMP, #pragma omp parallel for)"}
{"predict": "(1, TBB, tbb::concurrent_queue<Foo> queue;)", "label": "(4, TBB, tbb::concurrent_queue<Foo> queue;)"}
{"predict": "(5, CUDA, extern __shared__ uint64_t s_qiHat_mod_pj[];)", "label": "(5, CUDA, extern __shared__ uint64_t s_qiHat_mod_pj[];)"}
{"predict": "(13, MPI, MPI_Allreduce(buf, buf, N, MPIX_BFLOAT16, MPI_SUM, MPI_COMM_WORLD);); (23, MPI, MPI_Allreduce(buf_f16, buf_f16, N, MPIX_C_FLOAT16, MPI_SUM, MPI_COMM_WORLD);)", "label": "(10, MPI, MPI_Allreduce(MPI_IN_PLACE, buf, N, MPIX_BFLOAT16, MPI_SUM, comm);); (20, MPI, MPI_Allreduce(MPI_IN_PLACE, buf_f16, N, MPIX_C_FLOAT16, MPI_SUM, comm);)"}
{"predict": "(32, CUDA, CUDA_CHECK(cudaStreamSynchronize(stream));); (34, CUDA, CUDA_CHECK(cudaFree(d_data));)", "label": "(32, CUDA, CUDA_CHECK(cudaStreamSynchronize(stream));); (34, CUDA, CUDA_CHECK(cudaFree(d_data));)"}
{"predict": "(12, CUDA, PYCUDA_ASSERT_NOGIL(cudaStreamCreateWithFlags(&stream, flags | priority));)", "label": "(13, CUDA, PYCUDA_ASSERT_NOGIL(cudaStreamCreateWithPriority(&stream, flags, priority));)"}
{"predict": "(38, CUDA, cudaFree(res_dev);); (31, CUDA, cudaMalloc(&res_dev, sizeof(float));); (33, CUDA, cudaMemcpy(&res_host, res_dev, sizeof(float), cudaMemcpyDeviceToHost);)", "label": "(38, CUDA, cudaFree(res_dev);); (31, CUDA, cudaMalloc(&res_dev, sizeof(float));); (33, CUDA, cudaMemcpy(&res_host, res_dev, sizeof(float), cudaMemcpyDeviceToHost);)"}
{"predict": "(12, TBB, my_thread_array = tbb::cache_aligned_allocator<padded_private_worker>().allocate( my_n_thread );)", "label": "(12, TBB, my_thread_array = tbb::cache_aligned_allocator<padded_private_worker>().allocate( my_n_thread );)"}
{"predict": "(12, MPI, MPI_Iscan_c(sendbuf, recvbuf, count, datatype, MPI_SUM, comm, &req);); (8, MPI, MPI_Scan_c(sendbuf, recvbuf, count, datatype, MPI_SUM, comm);); (11, MPI, MPI_Wait(&req, MPI_STATUS_IGNORE);)", "label": "(9, MPI, MPI_Scan_c(sendbuf, recvbuf, count, datatype, MPI_SUM, comm);); (12, MPI, MPI_Wait(&req, MPI_STATUS_IGNORE);); (10, MPI, MPI_Iscan_c(sendbuf, recvbuf, count, datatype, MPI_SUM, comm, &req);)"}
{"predict": "(20, CUDA, getLastCudaError(\"generateSampleRanksKernel<0> failed\\n\");); (14, CUDA, getLastCudaError(\"generateSampleRanksKernel<1> failed\\n\");)", "label": "(15, CUDA, getLastCudaError(\"generateSampleRanksKernel<1U><<<>>> failed\\n\");); (19, CUDA, getLastCudaError(\"generateSampleRanksKernel<0U><<<>>> failed\\n\");)"}
{"predict": "(6, CUDA, st = cudaMalloc(&test_ptr, TEST_ALLOC_SIZE);); (26, CUDA, cudaFree(test_ptr);)", "label": "(6, CUDA, st = cudaMalloc(&test_ptr, TEST_ALLOC_SIZE);); (25, CUDA, cudaFree(test_ptr);)"}
{"predict": "(30, CUDA, cudaCheck(cudaGetLastError());)", "label": "(30, CUDA, cudaCheck(cudaGetLastError());)"}
{"predict": "(55, CUDA, CHECK_CUDA(cudaFree(imgs_dev));)", "label": "(35, CUDA, CHECK_CUDA(cudaMalloc((void**)&imgs_dev, img_N * 3 * img_w * img_h * sizeof(uchar)));)"}
{"predict": "(11, CUDA, CUCH(cudaMalloc(&ptr, plan_size * sizeof(int32_t)), mhcudaMemoryAllocationError);); (6, CUDA, CUCH(cudaSetDevice(devs[devi]), mhcudaNoSuchDeviceError);)", "label": "(12, CUDA, CUCH(cudaMalloc(&ptr, plan_size * sizeof(int32_t)), mhcudaMemoryAllocationFailure);); (6, CUDA, CUCH(cudaSetDevice(devs[devi]), mhcudaNoSuchDevice);)"}
{"predict": "(9, MPI, MPI_Comm_rank(comm, &comm_rank);); (10, MPI, MPI_Comm_size(comm, &comm_size);)", "label": "(9, MPI, MPI_Comm_rank(comm, &comm_rank);); (10, MPI, MPI_Comm_size(comm, &comm_size);)"}
{"predict": "(28, CUDA, CUDASimulation cudaSimulation(model);)", "label": "(28, CUDA, CUDASimulation cudaSimulation(model);)"}
{"predict": "(10, OpenMP, f = complex_cholesky_decomp(&p3, GSL_CHOLESKY_LOWER);)", "label": "(10, OpenMP, f = test_choleskyc_decomp_dim(&p3.matrix, 2 * 8.0 * GSL_DBL_EPSILON);)"}
{"predict": "(15, TBB, tbb::enumerable_thread_specific<size_t> num_high_degree_nodes(0);)", "label": "(15, TBB, tbb::enumerable_thread_specific<size_t> num_high_degree_nodes(0);)"}
{"predict": "(7, MPI, MPI_Info_get_string(info, key, MPI_MAX_INFO_VAL, buf, &flag);)", "label": "(7, MPI, MPI_Info_get(info, key, MPI_MAX_INFO_VAL, buf, &flag);)"}
{"predict": "(22, TBB, make_edge(input, doubler);); (23, TBB, make_edge(cuber, tbb::flow::input_port<2>(join));); (20, TBB, make_edge(squarer, tbb::flow::input_port<1>(join));); (18, TBB, make_edge(doubler, tbb::flow::input_port<0>(join));); (22, TBB, make_edge(join, summer);); (-3, TBB, using namespace tbb::flow;)", "label": "(1, TBB, using namespace oneapi::tbb::flow;)"}
{"predict": "(8, CUDA, cudaStreamSynchronize(LuH->A_gpu.cuStreams[0]);)", "label": "(8, CUDA, cudaStreamSynchronize(LuH->A_gpu.cuStreams[0]);)"}
{"predict": "(24, MPI, MPI_Send(unzval, lenv, MPI_DOUBLE, receiver, k, grid3d->zscp.comm);)", "label": "(24, MPI, MPI_Send(unzval, lenv, MPI_DOUBLE, receiver, k, grid3d->zscp.comm);)"}
{"predict": "(20, CUDA, CudaCheckError();); (23, CUDA, cudaFree(du_new_dev);)", "label": "(19, CUDA, CudaCheckError();); (23, CUDA, cudaFree(du_new_dev);)"}
{"predict": "(13, MPI, MPI_Allreduce(MPI_IN_PLACE,data,n,MPI_C_BOOL,MPI_LAND,ADDA_COMM);); (8, MPI, MPI_Abort(ADDA_COMM,1);)", "label": "(10, MPI, MPI_Barrier(MPI_COMM_WORLD);); (12, MPI, MPI_Allreduce(data,gr_comm_buf,n,mpi_bool,MPI_LAND,MPI_COMM_WORLD);)"}
{"predict": "(13, CUDA, CP_host->freeCudaMem();)", "label": "(13, CUDA, CP_host->freeCudaMem();)"}
{"predict": "(1, TBB, tbb::task_arena arena( 1 );)", "label": "(12, TBB, tbb::parallel_for( 0, N, 1, RoundingModeCheckBody(mode, sse_mode) );); (10, TBB, tbb::task_scheduler_init init;)"}
{"predict": "(7, OpenCL, clReleaseKernel_ExpectAndReturn(make_kernel(0), CL_SUCCESS);); (5, OpenCL, clReleaseDevice_ExpectAndReturn(make_device_id(0), CL_SUCCESS);)", "label": "(8, OpenCL, clReleaseKernel_ExpectAndReturn(make_kernel(0), CL_SUCCESS);); (6, OpenCL, clReleaseDevice_ExpectAndReturn(make_device_id(0), CL_SUCCESS);)"}
{"predict": "(22, MPI, *w = MPI_Wtime();)", "label": "(22, MPI, *w = MPI_Wtime();)"}
{"predict": "(2, CUDA, __shared__ half hs[32];)", "label": "(2, CUDA, extern __shared__ half  hs[][256];)"}
{"predict": "(10, CUDA, cudaStreamSynchronize(LU_v1->A_gpu.cuStreams[0]);)", "label": "(10, CUDA, cudaStreamSynchronize(LU_v1->A_gpu.cuStreams[0]);)"}
{"predict": "(2, OpenMP, omp_autotune(self, OMP_SCALE);)", "label": "(2, OpenMP, omp_autotune(self, OMP_SCALE);)"}
{"predict": "(12, CUDA, CUDA_CHECK(cudaFree(buffer_fp32));); (5, CUDA, CUDA_CHECK(cudaMalloc(&buffer_fp32, length * sizeof(float)));); (10, CUDA, CUDA_CHECK(cudaDeviceSynchronize());); (4, CUDA, CUDA_CHECK(cudaMemset(buffer_fp32, 0, length * sizeof(float)));); (11, CUDA, CUDA_CHECK(cudaMemcpy(buffer, buffer_fp32, length * sizeof(half), cudaMemcpyDeviceToDevice));); (8, CUDA, CUDA_CHECK(cudaMalloc(&buffer, length * sizeof(half)));); (10, CUDA, CUDA_CHECK(cudaFree(buffer));)", "label": "(7, CUDA, cudaMalloc((void **)&buffer_fp32, length * sizeof(float));); (9, CUDA, cudaMalloc((void **)&buffer, length * sizeof(T));); (10, CUDA, cudaFree(buffer_fp32);)"}
{"predict": "(23, OpenMP, #pragma omp teams distribute parallel for if(cond) firstprivate(fp) reduction(+:rd)); (15, OpenMP, #pragma omp target)", "label": "(16, OpenMP, #pragma omp target); (22, OpenMP, #pragma omp teams distribute parallel for if(cond) firstprivate(fp) reduction(+:rd))"}
{"predict": "(19, CUDA, cudaMemcpy(resf,dat,sizeof(unsigned)*2,cudaMemcpyDeviceToHost);)", "label": "(19, CUDA, cudaMemcpy(resf,dat,sizeof(unsigned)*2,cudaMemcpyDeviceToHost);)"}
{"predict": "(1, CUDA, __shared__ float cache[THREADS_PER_BLOCK];)", "label": "(5, CUDA, extern __shared__ float cache[];)"}
{"predict": "(12, TBB, my_thread_array = tbb::cache_aligned_allocator<padded_private_worker>().allocate( my_n_thread );)", "label": "(12, TBB, my_thread_array = tbb::cache_aligned_allocator<padded_private_worker>().allocate( my_n_thread );)"}
{"predict": "(12, OpenMP, #pragma omp target teams distribute parallel for copyin(ST<int>::s)); (15, OpenMP, #pragma omp target teams distribute parallel for copyin(m)); (16, OpenMP, #pragma omp target teams distribute parallel for copyin(argv[1])); (17, OpenMP, #pragma omp target teams distribute parallel for copyin(tmain)); (18, OpenMP, #pragma omp target teams distribute parallel for copyin(e, N)); (2, OpenMP, #pragma omp target teams distribute parallel for copyin()); (3, OpenMP, #pragma omp target teams distribute parallel for copyin(h,); (0, OpenMP, #pragma omp target teams distribute parallel for copyin()); (17, OpenMP, #pragma omp target teams distribute parallel for copyin(ST<int>::s)); (9, OpenMP, #pragma omp target teams distribute parallel for copyin(l)); (4, OpenMP, #pragma omp target teams distribute parallel for copyin(argc > 0 ? argv[1] : argv[2])); (10, OpenMP, #pragma omp target teams distribute parallel for copyin(h)); (-1, OpenMP, #pragma omp target teams distribute parallel for copyin(argc))", "label": "(16, OpenMP, #pragma omp target defaultmap (scalar:); (3, OpenMP, #pragma omp target defaultmap(); (10, OpenMP, #pragma omp target defaultmap(tofrom)); (11, OpenMP, #pragma omp target defaultmap(tofrom,); (16, OpenMP, #pragma omp target defaultmap(tofrom:scalar) defaultmap(tofrom:scalar)); (-3, OpenMP, #pragma omp target defaultmap); (19, OpenMP, #pragma omp target defaultmap(tofrom: something)); (11, OpenMP, #pragma omp target defaultmap(tofrom, scalar); (2, OpenMP, #pragma omp target defaultmap (tofrom:); (-3, OpenMP, #pragma omp target defaultmap()); (-2, OpenMP, #pragma omp target defaultmap(tofrom)"}
{"predict": "(45, MPI, MPI_Abort(MPI_COMM_WORLD, 1);)", "label": "(45, MPI, MPI_Abort(MPI_COMM_WORLD, 1);)"}
{"predict": "(6, MPI, MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);); (4, MPI, MPI_Comm_size(MPI_COMM_WORLD, &world_size);)", "label": "(6, MPI, MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);); (4, MPI, MPI_Comm_size(MPI_COMM_WORLD, &world_size);)"}
{"predict": "(7, CUDA, __shared__ block_radix_sort_t::TempStorage temp_storage;)", "label": "(7, CUDA, __shared__ block_radix_sort_t::TempStorage temp_storage;)"}
{"predict": "(8, TBB, tbb::flow::make_edge(my_queue, my_inspector);); (1, TBB, tbb::flow::broadcast_node<my_type> my_broadcast_node(g);); (2, TBB, tbb::flow::queue_node<my_type> my_queue(g);); (14, TBB, return (tbb::tick_count::now() - t0).seconds();); (16, TBB, my_graph_inspector.inspect_edges();); (-2, TBB, tbb::flow::graph my_graph_inspector(g);); (3, TBB, tbb::tick_count t0 = tbb::tick_count::now();)", "label": "(3, TBB, tbb::flow::broadcast_node<my_type> my_broadcast_node(g);); (7, TBB, const tbb::tick_count t0 = tbb::tick_count::now();); (14, TBB, return (tbb::tick_count::now() - t0).seconds();); (-1, TBB, tbb::flow::queue_node<my_type> my_queue(g);)"}
{"predict": "(8, OpenMP, #pragma omp target map(present, alloc: arr[0:0])); (6, OpenMP, #pragma omp target data map(alloc: arr[0:0]))", "label": "(8, OpenMP, #pragma omp target map(present, alloc: arr[0:0])); (6, OpenMP, #pragma omp target data map(alloc: arr[0:5])); (19, OpenMP, #pragma omp target data map(alloc: arr[0:0]))"}
{"predict": "(5, OpenMP, #pragma omp parallel num_threads(2)); (7, OpenMP, #pragma omp barrier); (-1, OpenMP, omp_set_nested(1);)", "label": "(5, OpenMP, #pragma omp parallel num_threads(2)); (3, OpenMP, omp_set_nested(1);)"}
{"predict": "(6, OpenMP, #pragma omp parallel for)", "label": "(6, OpenMP, #pragma omp parallel for)"}
{"predict": "(40, MPI, MPI_T_finalize();); (15, MPI, MPI_T_init_thread(required, &provided);)", "label": "(40, MPI, MPI_T_finalize();); (15, MPI, MPI_T_init_thread(required, &provided);)"}
{"predict": "(14, CUDA, return CUDA(cudaGetLastError());)", "label": "(14, CUDA, return CUDA(cudaGetLastError());)"}
{"predict": "(3, OpenMP, #pragma omp target teams); (5, OpenMP, #pragma omp parallel)", "label": "(1, OpenMP, #pragma omp target teams); (5, OpenMP, #pragma omp parallel)"}
{"predict": "(28, OpenCL, retVal = clReleaseMemObject(image);); (6, OpenCL, auto status = clGetDeviceInfo(&mockClDevice, CL_DEVICE_IMAGE_SUPPORT_INTEL, sizeof(imageSupportInfo), &imageSupportInfo, nullptr);)", "label": "(28, OpenCL, retVal = clReleaseMemObject(image);); (6, OpenCL, auto status = clGetDeviceInfo(&mockClDevice, CL_DEVICE_IMAGE_SUPPORT, sizeof(imageSupportInfo), &imageSupportInfo, nullptr);)"}
{"predict": "(27, MPI, MPI_Abort(MPI_COMM_WORLD, 1);)", "label": "(27, MPI, MPI_Abort(MPI_COMM_WORLD, 1);)"}
{"predict": "(3, CUDA, Check_CudaErroorFun(\"At the beginning.\");)", "label": "(3, CUDA, Check_CudaErroorFun(\"At the beginning.\");)"}
{"predict": "(24, CUDA, CUDASimulation cudaSimulation(model);)", "label": "(24, CUDA, CUDASimulation cudaSimulation(model);)"}
{"predict": "(15, CUDA, qmc_cuda::cuda_check(cudaGetLastError(), \"vKKwij_to_vwKiKj\");); (15, CUDA, qmc_cuda::cuda_check(cudaDeviceSynchronize(), \"vKKwij_to_vwKiKj\");)", "label": "(15, CUDA, qmc_cuda::cuda_check(cudaGetLastError(), \"vKKwij_to_vwKiKj\");); (15, CUDA, qmc_cuda::cuda_check(cudaDeviceSynchronize(), \"vKKwij_to_vwKiKj\");)"}
{"predict": "(9, OpenCL, auto userEvent = clCreateUserEvent(pContext, &retVal);); (30, OpenCL, retVal = clReleaseEvent(userEvent);)", "label": "(9, OpenCL, auto userEvent = clCreateUserEvent(pContext, &retVal);); (30, OpenCL, retVal = clReleaseEvent(userEvent);)"}
{"predict": "(10, OpenMP, #pragma omp teams distribute parallel for); (8, OpenMP, #pragma omp target); (12, OpenMP, #pragma omp teams distribute parallel for if (parallel: false))", "label": "(10, OpenMP, #pragma omp teams distribute parallel for); (8, OpenMP, #pragma omp target); (12, OpenMP, #pragma omp teams distribute parallel for if (parallel: false))"}
{"predict": "(18, CUDA, cudaDeviceSynchronize();)", "label": "(18, CUDA, ASSERT_EQ(cudaGetLastError(), cudaSuccess) << \"Kernel launch error.\";)"}
{"predict": "(5, MPI, MPI_Recv(buffer, n, MPI_INT, task, 123, MPI_COMM_WORLD, MPI_STATUS_IGNORE);)", "label": "(12, MPI, MPI_Barrier(MPI_COMM_WORLD);)"}
{"predict": "(15, CUDA, checkCudaErrors(cudaGetLastError());); (13, CUDA, checkCudaErrors(cudaStreamSynchronize(stream));)", "label": "(15, CUDA, checkCudaErrors(cudaGetLastError());); (13, CUDA, checkCudaErrors(cudaStreamSynchronize(stream));)"}
{"predict": "(4, CUDA, cudaDeviceSynchronize();)", "label": "(4, CUDA, cudaMemcpy(state.vx, state.dvx, size_f, cudaMemcpyDeviceToHost);); (4, CUDA, cudaMemcpy(state.vy, state.dvy, size_f, cudaMemcpyDeviceToHost);); (4, CUDA, cudaMemcpy(state.rho, state.drho, size_f, cudaMemcpyDeviceToHost);)"}
{"predict": "(6, MPI, MPI_Comm_rank(MPI_COMM_WORLD, &rank);)", "label": "(5, MPI, MPI_Comm_rank(MPI_COMM_WORLD, &rank);)"}
{"predict": "(14, MPI, MPI_Send(pre_info, 2, MPI_INT, 0, kTag, MPI_COMM_WORLD);)", "label": "(11, MPI, MPI_Send(pre_info, 2, MPI_INT, 0, kTag, MPI_COMM_WORLD);)"}
{"predict": "(6, MPI, MPI_Comm_rank(MPI_COMM_WORLD, &rank);); (6, MPI, MPI_Error_string(err, errorString, &errorStringLen);)", "label": "(6, MPI, MPI_Comm_rank(MPI_COMM_WORLD, &rank);); (6, MPI, MPI_Error_string(err, errorString, &errorStringLen);); (10, MPI, MPI_Abort(MPI_COMM_WORLD, -1);)"}
{"predict": "(7, MPI, MPI_Get_library_version(version, &resultlen);)", "label": "(7, MPI, MPI_Get_library_version(version, &resultlen);)"}
{"predict": "(11, OpenCL, auto commandQueue = clCreateCommandQueueWithProperties(context, clDevice, properties.data(), &retVal);); (21, OpenCL, clReleaseCommandQueue(commandQueue);)", "label": "(11, OpenCL, auto commandQueue = clCreateCommandQueueWithProperties(pContext, testedClDevice, properties.data(), &retVal);); (21, OpenCL, clReleaseCommandQueue(commandQueue);)"}
{"predict": "(3, MPI, MPI_Init(&argc, &argv);); (9, MPI, MPI_Finalize();)", "label": "(3, MPI, MPI_Init(&argc, &argv);); (9, MPI, MPI_Finalize();)"}
{"predict": "(10, OpenMP, #pragma omp parallel for)", "label": "(10, OpenMP, #pragma omp parallel for)"}
{"predict": "(6, OpenMP, #pragma omp parallel for)", "label": "(6, OpenMP, #pragma omp parallel for)"}
{"predict": "(11, CUDA, cudaStreamCreate(&stream);); (14, CUDA, cudaStreamDestroy(stream);)", "label": "(11, CUDA, cudaStreamCreate(&stream);); (14, CUDA, cudaStreamDestroy(stream);)"}
{"predict": "(3, CUDA, __shared__ clock_t s_clocks[THREADS_PER_BLOCK * sizeof(clock_t)];)", "label": "(3, CUDA, __shared__ clock_t s_clocks[32];)"}
{"predict": "(11, CUDA, extern __shared__ float sdata[];)", "label": "(11, CUDA, extern __shared__ float sdata[];)"}
{"predict": "(13, OpenCL, retVal = clReleaseMemObject(smallBuffer);); (2, OpenCL, cl_mem smallBuffer = clCreateBuffer(clContext, memProperties, 4096 * 10, nullptr, &retVal);); (16, OpenCL, EXPECT_EQ(clReleaseContext(context), CL_SUCCESS);)", "label": "(13, OpenCL, retVal = clReleaseMemObject(smallBuffer);); (17, OpenCL, EXPECT_EQ(clReleaseContext(context), CL_SUCCESS);); (1, OpenCL, cl_mem smallBuffer = clCreateBufferWithProperties(clContext, &memProperties, flags, size, hostPtr, &retVal);)"}
{"predict": "(6, TBB, tbb::task_group g;); (6, TBB, tbb::task_group_handle h1 = parallel_fib(n-1);); (6, TBB, tbb::task_group_handle h2 = parallel_fib(n-2);); (7, TBB, g.wait();); (10, TBB, tbb::task_group_result result = g.get_result();); (10, TBB, return result.value();); (6, TBB, x = h1.value();); (6, TBB, y = h2.value();)", "label": "(6, TBB, tbb::task_group g;); (6, TBB, tbb::task_handle h1 = make_task(g, x, n-1);); (6, TBB, tbb::task_handle h2 = make_task(g, y, n-2);)"}
{"predict": "(17, CUDA, cudaStreamDestroy(resources->exec_streams[i]);)", "label": "(17, CUDA, CUDA_FUNC(cudaStreamDestroy(resources->exec_streams[i]));)"}
{"predict": "(3, CUDA, using alloc = thrust::cuda::allocator<double>;); (11, CUDA, cudaDeviceSynchronize(); benchmark::DoNotOptimize(base(y)); benchmark::ClobberMemory();)", "label": "(3, CUDA, using alloc = thrust::cuda::allocator<double>;); (11, CUDA, cudaDeviceSynchronize(); benchmark::DoNotOptimize(y.base()); benchmark::ClobberMemory();)"}
{"predict": "(16, OpenMP, #pragma omp parallel for)", "label": "(16, OpenMP, #pragma omp parallel for)"}
{"predict": "(17, MPI, *v6 = MPIU_Make_Fint(MPI_Cart_create(MPI_Comm_f2c(*v1), *v2, l4, l5, (MPI_Info)(*v3), ierr));)", "label": "(17, MPI, *ierr = MPI_Cart_create( (MPI_Comm)(*v1), *v2, v3, l4, l5, (MPI_Comm *)(v6) );)"}
{"predict": "(16, CUDA, return CUDA(cudaGetLastError());)", "label": "(16, CUDA, return CUDA(cudaGetLastError());)"}
{"predict": "(23, MPI, MPI_Comm_rank(MPI_COMM_WORLD, &rank);)", "label": "(23, MPI, MPI_Comm_rank(MPI_COMM_WORLD, &rank);)"}
{"predict": "(7, CUDA, __shared__ block_radix_sort_t::TempStorage temp_storage;)", "label": "(7, CUDA, __shared__ block_radix_sort_t::TempStorage temp_storage;)"}
{"predict": "(8, OpenMP, #pragma omp parallel for)", "label": "(8, OpenMP, #pragma omp parallel for)"}
{"predict": "(13, OpenMP, #pragma omp parallel); (13, OpenMP, #pragma omp task if (task: false))", "label": "(13, OpenMP, #pragma omp parallel); (13, OpenMP, #pragma omp task if (task: false))"}
{"predict": "(6, CUDA, cudaMemcpy(data,datag+inidata,sizeof(float3)*ndata,cudaMemcpyDeviceToHost);); (6, CUDA, fcuda::Check_CudaErroorFun(\"DgReduSumFloat3\");)", "label": "(7, CUDA, fcuda::Check_CudaErroorFun(\"DgReduSumFloat3\");); (5, CUDA, cudaMemcpy(data,datag+inidata,sizeof(float3)*ndata,cudaMemcpyDeviceToHost);)"}
{"predict": "(125, OpenMP, #define GOMP_CRITICAL_SWP(FLAG))", "label": "(127, OpenMP, #define GOMP_CRITICAL_SWP(FLAG))"}
{"predict": "(33, CUDA, CUDA_CHECK(cudaStreamSynchronize(stream));); (35, CUDA, CUDA_CHECK(cudaFree(d_data));)", "label": "(33, CUDA, CUDA_CHECK(cudaStreamSynchronize(stream));); (35, CUDA, CUDA_CHECK(cudaFree(d_data));)"}
{"predict": "(10, OpenMP, #pragma omp parallel for private(i) schedule(static,7)); (12, OpenMP, #pragma omp flush)", "label": "(14, OpenMP, #pragma omp flush); (9, OpenMP, #pragma omp parallel for reduction(+:sum) schedule(static,1) private(i) private(i2))"}
{"predict": "(3, OpenMP, #pragma omp target device(0)); (13, OpenMP, #pragma omp target device(1))", "label": "(3, OpenMP, #pragma omp target device(0)); (13, OpenMP, #pragma omp target device(1))"}
{"predict": "(15, OpenMP, #pragma omp target update from(C) device(0)); (3, OpenMP, #pragma omp target data map(to:tt.p1[0:10]) map(from:C[0:10]) device(0)); (10, OpenMP, #pragma omp target parallel for device(0))", "label": "(12, OpenMP, #pragma omp target map(tofrom: C) map(to: tt, tt.p1[:10]))"}
{"predict": "(10, TBB, tbb::task_scheduler_init init(1);); (13, TBB, tbb::tick_count t0 = tbb::tick_count::now();); (19, TBB, std::cout << \"done\" << std::endl << \"elapsed time: \" << (tbb::tick_count::now() - t0).seconds() << \" seconds\" << std::endl;); (7, TBB, tbb::task* m = new(tbb::task::allocate_root()) tbb::empty_task;)", "label": "(12, TBB, tbb::mutex *m = new tbb::mutex;)"}
{"predict": "(19, MPI, MPI_Abort(MPI_COMM_WORLD, 1);)", "label": "(19, MPI, MPI_Abort(MPI_COMM_WORLD, 1);)"}
{"predict": "(24, MPI, MPI_Allreduce( &s, &berr, 1, MPI_FLOAT, MPI_MAX, grid->comm );)", "label": "(24, MPI, MPI_Allreduce( &s, &berr, 1, MPI_FLOAT, MPI_MAX, grid->comm );)"}
{"predict": "(16, CUDA, CUDA_CHECK(cudaGetLastError());)", "label": "(16, CUDA, CUDA_CHECK(cudaGetLastError());)"}
{"predict": "(6, OpenMP, int _dev_thread_num = omp_get_num_threads();); (4, OpenMP, #pragma omp parallel); (6, OpenMP, int _dev_thread_id = omp_get_thread_num();)", "label": "(13, OpenMP, int _dev_thread_id = omp_get_thread_num();); (11, OpenMP, int _dev_thread_num = omp_get_num_threads();)"}
{"predict": "(14, CUDA, cudaError_t err = cudaMalloc(&m_histogram, sizeof(int) * 256 * maxBatchSize);)", "label": "(14, CUDA, cudaError_t err = cudaMalloc(&m_histogram, sizeof(int) * 256 * maxBatchSize);)"}
{"predict": "(21, CUDA, qmc_cuda::cuda_check(cudaDeviceSynchronize(), \"KaKjw_to_KKwaj\");); (19, CUDA, qmc_cuda::cuda_check(cudaGetLastError(), \"KaKjw_to_KKwaj\");)", "label": "(21, CUDA, qmc_cuda::cuda_check(cudaDeviceSynchronize(), \"KaKjw_to_KKwaj\");); (19, CUDA, qmc_cuda::cuda_check(cudaGetLastError(), \"KaKjw_to_KKwaj\");)"}
{"predict": "(18, TBB, tbb::spin_mutex::scoped_lock lock(*rMutex);)", "label": "(18, TBB, tbb::spin_mutex::scoped_lock lock(*rMutex);)"}
{"predict": "(20, CUDA, cudaMalloc((void **)&d_RanksB, MAX_SAMPLE_COUNT * sizeof(uint));); (20, CUDA, cudaMalloc((void **)&d_LimitsA, MAX_SAMPLE_COUNT * sizeof(uint));); (18, CUDA, cudaMalloc((void **)&d_RanksA, MAX_SAMPLE_COUNT * sizeof(uint));); (18, CUDA, cudaMalloc((void **)&d_LimitsB, MAX_SAMPLE_COUNT * sizeof(uint));)", "label": "(21, CUDA, checkCudaErrors(cudaMalloc((void **)&d_LimitsA, MAX_SAMPLE_COUNT * sizeof(uint)));); (19, CUDA, checkCudaErrors(cudaMalloc((void **)&d_RanksB,  MAX_SAMPLE_COUNT * sizeof(uint)));); (17, CUDA, checkCudaErrors(cudaMalloc((void **)&d_RanksA,  MAX_SAMPLE_COUNT * sizeof(uint)));); (19, CUDA, checkCudaErrors(cudaMalloc((void **)&d_LimitsB, MAX_SAMPLE_COUNT * sizeof(uint)));)"}
{"predict": "(6, MPI, MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);); (4, MPI, MPI_Comm_size(MPI_COMM_WORLD, &world_size);)", "label": "(6, MPI, MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);); (4, MPI, MPI_Comm_size(MPI_COMM_WORLD, &world_size);)"}
{"predict": "(2, MPI, MPIDataCommunicator mpi_world_communicator(MPI_COMM_WORLD);)", "label": "(2, MPI, MPIDataCommunicator mpi_world_communicator(MPI_COMM_WORLD);)"}
{"predict": "(8, MPI, MPI_Reduce_local(inbuf, inoutbuf, count, datatype, MPI_SUM);)", "label": "(8, MPI, MPI_Reduce_local_c(inbuf, inoutbuf, count, datatype, MPI_SUM);)"}
{"predict": "(13, CUDA, CUDASimulation cudaSimulation(model);)", "label": "(13, CUDA, CUDASimulation cudaSimulation(model);)"}
{"predict": "(19, MPI, MPI_Grequest_complete(aio_reqlist[i]->req);)", "label": "(19, MPI, MPI_Grequest_complete(aio_reqlist[i]->req);)"}
{"predict": "(1, OpenMP, #pragma omp parallel firstprivate(a, b, c)); (4, OpenMP, #pragma omp parallel firstprivate(a, b))", "label": "(1, OpenMP, #pragma omp parallel firstprivate(a, b, c, e)); (4, OpenMP, #pragma omp parallel firstprivate(a, b, c))"}
{"predict": "(22, CUDA, cudaCheck(cudaGetLastError());)", "label": "(45, CUDA, cudaCheck(cudaGetLastError());)"}
{"predict": "(13, CUDA, CP_host->freeCudaMem();)", "label": "(13, CUDA, CP_host->freeCudaMem();)"}
{"predict": "(11, OpenMP, #pragma omp for); (3, OpenMP, #pragma omp tile sizes(5))", "label": "(6, OpenMP, #pragma omp tile sizes(5)); (0, OpenMP, #pragma omp for)"}
{"predict": "(8, MPI, rc = MPI_Type_get_extent(type, &tmp_lb, &attr->child_type_extent);)", "label": "(8, MPI, rc = MPI_Type_get_extent(type, &tmp_lb, &attr->child_type_extent);)"}
{"predict": "(5, OpenMP, #pragma omp target teams distribute simd reduction(+: sivar))", "label": "(5, OpenMP, #pragma omp target teams distribute simd reduction(+: sivar))"}
{"predict": "(2, CUDA, extern __shared__ float share_mem[];)", "label": "(7, CUDA, extern __shared__ float share_mem[];)"}
{"predict": "(8, OpenMP, #pragma omp parallel for)", "label": "(7, OpenMP, #pragma omp parallel for)"}
{"predict": "(4, MPI, MPI_Reduce( &SCT->commVolFactor, &cvolFactor,  1, MPI_DOUBLE, MPI_SUM, 0, grid3d->comm );); (5, MPI, MPI_Reduce( &SCT->commVolRed, &cvolRed,  1, MPI_DOUBLE, MPI_SUM, 0, grid3d->comm );)", "label": "(4, MPI, MPI_Reduce( &SCT->commVolFactor, &cvolFactor,  1, MPI_DOUBLE, MPI_SUM, 0, grid3d->comm );); (5, MPI, MPI_Reduce( &SCT->commVolRed, &cvolRed,  1, MPI_DOUBLE, MPI_SUM, 0, grid3d->comm );)"}
{"predict": "(10, TBB, tbb::task_group g;)", "label": "(5, TBB, if(tbb::is_current_task_group_canceling()) return;)"}
{"predict": "(14, CUDA, CUDASimulation cudaSimulation(model);)", "label": "(14, CUDA, CUDASimulation cudaSimulation(model);)"}
{"predict": "(17, MPI, MPI_Finalize();); (2, MPI, MPI_Init(&argc,&argv);)", "label": "(17, MPI, MPI_Finalize();); (2, MPI, MPI_Init(&argc,&argv);)"}
{"predict": "(6, MPI, MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);)", "label": "(7, MPI, MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);)"}
{"predict": "(43, CUDA, CSC(cudaGetLastError(), STATUS_FAILURE);)", "label": "(43, CUDA, CSC(cudaGetLastError(), STATUS_FAILURE);)"}
{"predict": "(16, CUDA, CudaFile aCudaFile( aReader, GPUSPHOptions(), aTemplDir );)", "label": "(16, CUDA, CudaFile aCudaFile( aReader, GPUSPHOptions(), aTemplDir );)"}
{"predict": "(11, OpenMP, #pragma omp parallel for reduction(+:entropy))", "label": "(11, OpenMP, #pragma omp parallel for reduction(+ : entropy))"}
{"predict": "(6, MPI, MPI_Comm_dup(MPI_COMM_SELF, &lwgrp_comm_self);); (14, MPI, MPI_Comm_free(&lwgrp_comm_self);)", "label": "(6, MPI, MPI_Comm_dup(MPI_COMM_SELF, &lwgrp_comm_self);)"}
{"predict": "(4, OpenMP, #pragma omp target teams distribute parallel for private(g, g1, sivar))", "label": "(4, OpenMP, #pragma omp target teams distribute parallel for private(g, g1, sivar))"}
{"predict": "(6, CUDA, CUDA_CHECK(cudaMemGetInfo(&free, &total));); (5, CUDA, CUDA_CHECK(cudaDeviceSynchronize());)", "label": "(6, CUDA, cudaCheck(cudaMemGetInfo(&free, &total));)"}
{"predict": "(13, CUDA, fprintf(stderr, \"CUDA kernel failed : %s\\n\", cudaGetErrorString(err));); (10, CUDA, auto err = cudaGetLastError();)", "label": "(13, CUDA, fprintf(stderr, \"CUDA kernel failed : %s\\n\", cudaGetErrorString(err));); (10, CUDA, auto err = cudaGetLastError();)"}
{"predict": "(22, MPI, MPI_Comm_rank(MPI_COMM_WORLD, &mpi_rank);); (22, MPI, MPI_Comm_size(MPI_COMM_WORLD, &mpi_size);)", "label": "(22, MPI, MPI_Comm_rank(MPI_COMM_WORLD, &mpi_rank);); (22, MPI, MPI_Comm_size(MPI_COMM_WORLD, &mpi_size);)"}
{"predict": "(11, MPI, MPI_Comm_size(comm, &npes);)", "label": "(11, MPI, MPI_Comm_size(comm, &npes);)"}
{"predict": "(7, OpenMP, std::vector<BabelFlow::Payload> comp_outputs( 1 );)", "label": "(6, OpenMP, std::vector<BabelFlow::Payload> comp_outputs( 1 );)"}
{"predict": "(7, CUDA, RAFT_CUDA_TRY(cudaStreamSynchronize(stream));)", "label": "(6, CUDA, RAFT_CUDA_TRY(cudaStreamSynchronize(stream));)"}
{"predict": "(2, MPI, MPIDataCommunicator mpi_world_communicator(MPI_COMM_WORLD);)", "label": "(2, MPI, MPIDataCommunicator mpi_world_communicator(MPI_COMM_WORLD);)"}
{"predict": "(76, OpenMP, #define OP_GOMP_CRITICAL_CPT(TYPE, OP, FLAG))", "label": "(76, OpenMP, #define OP_GOMP_CRITICAL_CPT(TYPE, OP, FLAG))"}
{"predict": "(1, CUDA, __shared__ float cache[threadsPerBlock];)", "label": "(1, CUDA, __shared__ float cache[threadsPerBlock];)"}
{"predict": "(33, CUDA, cudaFree( dptrForce );); (31, CUDA, cudaFree( dptrPosMass );)", "label": "(33, CUDA, cudaFree( dptrPosMass );); (33, CUDA, cudaFree( dptrForce );)"}
{"predict": "(3, OpenMP, #pragma omp target teams distribute parallel for map(tofrom:sum) reduction(+:sum)); (8, OpenMP, #pragma omp target teams distribute parallel for reduction(+:gsum))", "label": "(3, OpenMP, #pragma omp parallel for reduction(+:sum)); (8, OpenMP, #pragma omp target teams distribute parallel for reduction(+:gsum))"}
{"predict": "(33, MPI, MPI_Bcast(&rc, 1, MPI_INT, 0, scr_storedesc_cntl->comm);)", "label": "(33, MPI, MPI_Bcast(&rc, 1, MPI_INT, 0, scr_storedesc_cntl->comm);)"}
{"predict": "(11, TBB, test_resets<int,tbb::flow::queue_node<int> >();); (12, TBB, test_buffer_extract<tbb::flow::queue_node<int> >().run_tests();); (9, TBB, test_resets<float,tbb::flow::queue_node<float> >();); (11, TBB, test_extract<tbb::flow::queue_node<int> >().run_tests();); (7, TBB, test_resets<double,tbb::flow::queue_node<double> >();)", "label": "(10, TBB, test_extract<tbb::flow::rejecting>();); (10, TBB, test_extract<tbb::flow::queueing>();)"}
{"predict": "(4, OpenMP, #pragma omp parallel num_threads(2)); (2, OpenMP, omp_set_nested(1);)", "label": "(5, OpenMP, #pragma omp parallel num_threads(2)); (1, OpenMP, omp_set_nested(1);); (1, OpenMP, omp_set_max_active_levels(1);)"}
{"predict": "(9, TBB, tbb::concurrent_set<int> static_init_time_set;)", "label": "(7, TBB, tbb::concurrent_unordered_set<int> static_init_time_set;)"}
{"predict": "(179, CUDA, cudaMemcpy(z_cu, z, shape.Z_len * sizeof(DT), cudaMemcpyHostToDevice);); (271, CUDA, cudaFree(x_cu);); (172, CUDA, cudaMalloc(&x_cu, shape.X_len * sizeof(ST));); (175, CUDA, cudaMemcpy(y_cu, y, shape.Y_len * sizeof(ST), cudaMemcpyHostToDevice);); (173, CUDA, cudaMemcpy(x_cu, x, shape.X_len * sizeof(ST), cudaMemcpyHostToDevice);); (268, CUDA, cudaFree(y_cu);); (170, CUDA, cudaMalloc(&z_cu, shape.Z_len * sizeof(DT));); (168, CUDA, cudaMalloc(&y_cu, shape.Y_len * sizeof(ST));); (178, CUDA, CHECK_HIEDNN(hiednnCreateCudaHandle(&handle));); (270, CUDA, CHECK_HIEDNN(hiednnDestroyCudaHandle(handle));); (264, CUDA, cudaFree(z_cu);)", "label": "(169, CUDA, cudaMemcpy(z_cu, z, shape.Z_len * sizeof(DT), cudaMemcpyHostToDevice);); (261, CUDA, cudaFree(x_cu);); (162, CUDA, cudaMalloc(&x_cu, shape.X_len * sizeof(ST));); (165, CUDA, cudaMemcpy(y_cu, y, shape.Y_len * sizeof(ST), cudaMemcpyHostToDevice);); (163, CUDA, cudaMemcpy(x_cu, x, shape.X_len * sizeof(ST), cudaMemcpyHostToDevice);); (258, CUDA, cudaFree(y_cu);); (160, CUDA, cudaMalloc(&z_cu, shape.Z_len * sizeof(DT));); (158, CUDA, cudaMalloc(&y_cu, shape.Y_len * sizeof(ST));); (168, CUDA, CHECK_HIEDNN(hiednnCreateCudaHandle(&handle));); (260, CUDA, CHECK_HIEDNN(hiednnDestroyCudaHandle(handle));); (254, CUDA, cudaFree(z_cu);)"}
{"predict": "(1, TBB, using tbb::detail::d2::range_based_for_support_tests::ch_map;)", "label": "(4, TBB, using ch_map = tbb::concurrent_hash_map<int,int>;)"}
{"predict": "(5, OpenMP, #pragma omp parallel master taskloop); (1, OpenMP, #pragma omp parallel)", "label": "(2, OpenMP, #pragma omp parallel); (4, OpenMP, #pragma omp parallel master taskloop)"}
{"predict": "(9, OpenMP, #pragma omp target data map(tofrom: i) use_device_ptr(k) use_device_addr(i,j)); (11, OpenMP, #pragma omp target data map(tofrom: i) use_device_ptr(z) use_device_addr(i,j,k[:i])); (7, OpenMP, #pragma omp target data map(tofrom: i) use_device_ptr(j) use_device_addr(i)); (11, OpenMP, #pragma omp target data map(tofrom: i) use_device_ptr(k) use_device_addr(i,j,k[:i])); (5, OpenMP, #pragma omp target data map(tofrom: i) use_device_ptr(i) use_device_addr())", "label": "(9, OpenMP, #pragma omp target data map(tofrom: i) use_device_ptr(k) use_device_addr(i, j)); (13, OpenMP, #pragma omp target data map(tofrom: i) use_device_ptr(z) use_device_addr(i, j, k[:i]))"}
{"predict": "(63, OpenMP, #define OP_GOMP_CRITICAL_READ(OP, FLAG))", "label": "(63, OpenMP, #define OP_GOMP_CRITICAL_READ(OP, FLAG))"}
{"predict": "(2, OpenMP, omp_autotune(self, OMP_SCALE);)", "label": "(2, OpenMP, omp_autotune(self, OMP_SCALE);)"}
{"predict": "(13, MPI, MPI_Wait(&request, &status);); (6, MPI, MPI_Isend(p->buff, p->bufflen, MPI_BYTE, p->prot.nbor, 1, MPI_COMM_WORLD, &request);); (6, MPI, MPI_Irecv(p->buff1, p->bufflen, MPI_BYTE, p->prot.nbor, 1, MPI_COMM_WORLD, &request);)", "label": "(9, MPI, MPI_Wait(&request, &status);); (6, MPI, MPI_Irecv(p->buff1, p->bufflen, MPI_BYTE, p->prot.nbor, 1, MPI_COMM_WORLD, &request);); (6, MPI, MPI_Send(p->buff, p->bufflen, MPI_BYTE, p->prot.nbor, 1, MPI_COMM_WORLD);)"}
{"predict": "(6, OpenMP, omp_set_dynamic(0);)", "label": "(6, OpenMP, omp_set_dynamic(0);)"}
{"predict": "(14, CUDA, qmc_cuda::cuda_check(cudaDeviceSynchronize());); (12, CUDA, qmc_cuda::cuda_check(cudaGetLastError());)", "label": "(14, CUDA, qmc_cuda::cuda_check(cudaDeviceSynchronize());); (12, CUDA, qmc_cuda::cuda_check(cudaGetLastError());)"}
{"predict": "(6, TBB, tbb::flow::queue_node< q3_input_type >  q3(g);); (7, TBB, tbb::flow::make_edge( q3, my_split );)", "label": "(6, TBB, tbb::flow::queue_node< q3_input_type >  q3(g);); (7, TBB, tbb::flow::make_edge( q3, my_split );)"}
{"predict": "(6, OpenMP, #pragma omp atomic)", "label": "(3, OpenMP, #pragma omp atomic)"}
{"predict": "(15, CUDA, qmc_cuda::cuda_check(cudaGetLastError(), \"batched_dot_wabn_wban\");); (15, CUDA, qmc_cuda::cuda_check(cudaDeviceSynchronize(), \"batched_dot_wabn_wban\");)", "label": "(16, CUDA, qmc_cuda::cuda_check(cudaDeviceSynchronize(), \"batched_dot_wabn_wban\");); (14, CUDA, qmc_cuda::cuda_check(cudaGetLastError(), \"batched_dot_wabn_wban\");)"}
{"predict": "(14, OpenMP, #pragma omp taskloop simd shared(c) num_tasks(a) simdlen(8) safelen(64))", "label": "(14, OpenMP, #pragma omp master taskloop shared(c) num_tasks(a))"}
{"predict": "(2, OpenMP, #pragma omp parallel); (3, OpenMP, #pragma omp master taskloop simd)", "label": "(4, OpenMP, #pragma omp master taskloop simd); (1, OpenMP, #pragma omp parallel)"}
{"predict": "(8, CUDA, cudaDeviceSynchronize();); (6, CUDA, getLastCudaError(\"launch_kernel failed\");)", "label": "(7, CUDA, cudaDeviceSynchronize();); (7, CUDA, getLastCudaError(\"launch_kernel failed\");)"}
{"predict": "(6, TBB, tbb::global_control c(tbb::global_control::max_allowed_parallelism,2);)", "label": "(6, TBB, tbb::global_control global_limit(tbb::global_control::max_allowed_parallelism, idx);)"}
{"predict": "(39, CUDA, cudaFree(res_dev);); (32, CUDA, cudaMalloc(&res_dev, sizeof(float));); (34, CUDA, cudaMemcpy(&res_host, res_dev, sizeof(float), cudaMemcpyDeviceToHost);)", "label": "(39, CUDA, cudaFree(res_dev);); (32, CUDA, cudaMalloc(&res_dev, sizeof(float));); (34, CUDA, cudaMemcpy(&res_host, res_dev, sizeof(float), cudaMemcpyDeviceToHost);)"}
{"predict": "(16, MPI, MPI_Error_string(err, msg, &len);); (8, MPI, err = MPI_Probe(MPI_COMM_WORLD, 99, MPI_INT, &status);)", "label": "(16, MPI, MPI_Error_string(err, msg, &len);); (8, MPI, err = MPI_Probe(-80, 1, MPI_COMM_WORLD, &status);); (5, MPI, MPI_Comm_set_errhandler(MPI_COMM_WORLD, MPI_ERRORS_RETURN);)"}
{"predict": "(16, CUDA, CUDA_CHECK(cudaGetLastError());)", "label": "(16, CUDA, CUDA_CHECK(cudaGetLastError());)"}
{"predict": "(9, TBB, oneapi::tbb::range<DimAmount> r(data);)", "label": "(10, TBB, range_t r = utils_t::make_range((1 << (20 / DimAmount - 1)) - DimAmount, false, &MakeInt, oneapi::tbb::detail::make_index_sequence<DimAmount>());); (1, TBB, using range_t = oneapi::tbb::blocked_nd_range<int, DimAmount>;)"}
{"predict": "(33, MPI, MPI_Barrier(scr_comm_world);)", "label": "(33, MPI, MPI_Barrier(scr_comm_world);)"}
{"predict": "(16, OpenCL, context = clCreateContext(nullptr, 1, &device, nullptr, nullptr, &error);)", "label": "(16, OpenCL, context = clCreateContext(nullptr, 1, &device, nullptr, nullptr, &error);)"}
{"predict": "(24, OpenCL, clReleaseEvent(event);)", "label": "(24, OpenCL, clReleaseEvent(event);)"}
{"predict": "(19, OpenCL, retVal = clEnqueueUnmapMemObject(cmdQ.get(), buffer.get(), mappedPtr, 1, &clUnmapEvent, nullptr);); (10, OpenCL, void *mappedPtr = clEnqueueMapBuffer(cmdQ.get(), buffer.get(), CL_FALSE, CL_MAP_WRITE, offset, size, 1, &clMapEvent, nullptr, &retVal);)", "label": "(19, OpenCL, retVal = clEnqueueUnmapMemObject(cmdQ.get(), buffer.get(), mappedPtr, 1, &clUnmapEvent, nullptr);); (10, OpenCL, void *mappedPtr = clEnqueueMapBuffer(cmdQ.get(), buffer.get(), CL_FALSE, CL_MAP_WRITE, offset, size, 1, &clMapEvent, nullptr, &retVal);)"}
{"predict": "(16, OpenCL, retVal = clEnqueueUnmapMemObject(cmdQ.get(), image.get(), mappedPtr, 0, nullptr, nullptr);); (8, OpenCL, void *mappedPtr = clEnqueueMapImage(cmdQ.get(), image.get(), CL_TRUE, CL_MAP_READ, &origin[0], &region[0], nullptr, nullptr, 0, nullptr, nullptr, &retVal);)", "label": "(16, OpenCL, retVal = clEnqueueUnmapMemObject(cmdQ.get(), image.get(), mappedPtr, 0, nullptr, nullptr);); (8, OpenCL, void *mappedPtr = clEnqueueMapImage(cmdQ.get(), image.get(), CL_TRUE, CL_MAP_READ, &origin[0], &region[0], nullptr, nullptr, 0, nullptr, nullptr, &retVal);)"}
{"predict": "(4, CUDA, cudaError_t result = cudaSetDevice(i);); (6, CUDA, nvError(\"cudaSetDevice(%i) failed\\n -> %s\\n -> %s\", i, cudaGetErrorString(result), cudaGetErrorInfo(result));)", "label": "(4, CUDA, cudaError_t result = cudaSetDevice(i);); (6, CUDA, nvDebug(\"*** CUDA Error: %s\\n\", cudaGetErrorString(result));)"}
{"predict": "(6, OpenMP, #pragma omp target map(from:c))", "label": "(6, OpenMP, #pragma omp target map(from:c))"}
{"predict": "(20, CUDA, getLastCudaError(\"mergeRanksAndIndicesKernel() execution failed\\n\");); (26, CUDA, getLastCudaError(\"mergeRanksAndIndicesKernel() execution failed for second kernel\\n\");)", "label": "(28, CUDA, getLastCudaError(\"mergeRanksAndIndicesKernel(B)<<<>>> failed\\n\");); (18, CUDA, getLastCudaError(\"mergeRanksAndIndicesKernel(A)<<<>>> failed\\n\");)"}
{"predict": "(8, CUDA, checkCudaErrors(cudaFuncGetAttributes(&attr,ptr));); (6, CUDA, checkCudaErrors(cudaOccupancyMaxActiveBlocksPerMultiprocessor(&qblocksize,ptr,0,0));)", "label": "(9, CUDA, cudaFuncGetAttributes(&attr,(void*)ptr);); (14, CUDA, fcuda::Check_CudaErroorFun(\"Error collecting kernel information.\");); (5, CUDA, cudaOccupancyMaxPotentialBlockSize(&mingridsize,&qblocksize,(void*)ptr,0,0);)"}
{"predict": "(6, CUDA, extent = make_cudaExtent(30, 40, 0);); (3, CUDA, cudaExtent extent = make_cudaExtent(10, 20, 0);)", "label": "(6, CUDA, extent = make_cudaExtent(30, 40, 0);); (3, CUDA, cudaExtent extent = make_cudaExtent(10, 20, 0);)"}
{"predict": "(6, MPI, MPI_Win_get_attr(win, key[i], &val_p, &flag);)", "label": "(6, MPI, MPI_Win_get_attr(win, key[i], &val_p, &flag);)"}
{"predict": "(23, CUDA, cudaMemcpy(output, data, copySize, cudaMemcpyDeviceToDevice);); (20, CUDA, cudaMemcpy(workspace, transformCoeff, sizeof(int)*nOutputDims,cudaMemcpyHostToDevice );)", "label": "(23, CUDA, cudaMemcpy(output, data, copySize, cudaMemcpyDeviceToDevice);); (20, CUDA, cudaMemcpy(workspace, transformCoeff, sizeof(int)*nOutputDims,cudaMemcpyHostToDevice );)"}
{"predict": "(3, OpenMP, #pragma omp target map(tofrom : tmp)); (12, OpenMP, #pragma omp target parallel map(tofrom : tmp))", "label": "(12, OpenMP, #pragma omp target map(tofrom: N) map(from:tmp)); (2, OpenMP, #pragma omp target map(to: N) map(tofrom: tmp))"}
{"predict": "(12, TBB, g.reset(tbb::flow::rf_clear_edges);); (4, TBB, tbb::flow::queue_node<int> qout(g);); (5, TBB, tbb::flow::make_edge(on,qout);); (0, TBB, tbb::flow::graph g;)", "label": "(12, TBB, g.reset(tbb::flow::rf_clear_edges);); (4, TBB, tbb::flow::queue_node<int> qout(g);); (5, TBB, tbb::flow::make_edge(on,qout);); (0, TBB, tbb::flow::graph g;)"}
{"predict": "(31, CUDA, CSC(cudaGetLastError(), STATUS_FAILURE);)", "label": "(34, CUDA, CSC(cudaGetLastError(), STATUS_FAILURE);)"}
{"predict": "(4, OpenMP, #pragma omp target teams distribute parallel for reduction(+:tmp2)); (8, OpenMP, #pragma omp target teams distribute parallel for reduction(+:tmp) map(tofrom: M))", "label": "(8, OpenMP, #pragma omp target teams distribute parallel for reduction(+:tmp) map(A, N, M) map(tofrom:M))"}
{"predict": "(2, TBB, tbb::task_arena sequential_arena(1);)", "label": "(1, TBB, tbb::task_arena sequential_arena(1);)"}
{"predict": "(7, CUDA, __shared__ float shared_val[32];)", "label": "(4, CUDA, __shared__ float shared_val[32];)"}
{"predict": "(3, OpenMP, #pragma omp target)", "label": "(3, OpenMP, #pragma omp target)"}
{"predict": "(15, CUDA, extern __shared__ float sdata[];)", "label": "(15, CUDA, extern __shared__ float sdata[];)"}
{"predict": "(20, CUDA, getLastCudaError(\"mergeElementaryIntervalsKernel<0> failed\\n\");); (14, CUDA, getLastCudaError(\"mergeElementaryIntervalsKernel<1> failed\\n\");)", "label": "(15, CUDA, getLastCudaError(\"mergeElementaryIntervalsKernel<1> failed\\n\");); (19, CUDA, getLastCudaError(\"mergeElementaryIntervalsKernel<0> failed\\n\");)"}
{"predict": "(7, CUDA, __shared__ block_radix_sort_t::TempStorage temp_storage;)", "label": "(7, CUDA, __shared__ block_radix_sort_t::TempStorage temp_storage;)"}
{"predict": "(38, CUDA, CUDA_CHECK(cudaStreamSynchronize(stream));); (40, CUDA, CUDA_CHECK(cudaFree(d_data));)", "label": "(38, CUDA, CUDA_CHECK(cudaStreamSynchronize(stream));); (40, CUDA, CUDA_CHECK(cudaFree(d_data));)"}
{"predict": "(10, OpenCL, auto mappedPtr = clEnqueueMapBuffer(&cmdQ, buffer.get(), CL_TRUE, CL_MAP_WRITE, 0, 1, 0, nullptr, nullptr, &retVal);); (12, OpenCL, retVal = clEnqueueUnmapMemObject(&cmdQ, buffer.get(), mappedPtr, 0, nullptr, nullptr);)", "label": "(10, OpenCL, auto mappedPtr = clEnqueueMapBuffer(&cmdQ, buffer.get(), CL_TRUE, CL_MAP_READ, 0, 1, 0, nullptr, nullptr, &retVal);); (12, OpenCL, retVal = clEnqueueUnmapMemObject(&cmdQ, buffer.get(), mappedPtr, 0, nullptr, nullptr);)"}
{"predict": "(12, TBB, tbb::task_scheduler_init init(number_of_threads);)", "label": "(10, TBB, static const size_t number_of_threads = 8 * tbb::task_scheduler_init::default_num_threads();)"}
{"predict": "(34, CUDA, CUDA_CHECK(cudaStreamSynchronize(stream));); (36, CUDA, CUDA_CHECK(cudaFree(d_data));)", "label": "(34, CUDA, CUDA_CHECK(cudaStreamSynchronize(stream));); (36, CUDA, CUDA_CHECK(cudaFree(d_data));)"}
{"predict": "(15, CUDA, cudaDeviceSynchronize();)", "label": "(15, CUDA, cudaDeviceSynchronize();)"}
{"predict": "(12, OpenMP, #pragma omp parallel for private(i,j,k) schedule(static,1))", "label": "(12, OpenMP, #pragma omp parallel for private(i,j,k) num_threads(dtn(border, 1)))"}
{"predict": "(4, CUDA, extern __shared__ int shared[];)", "label": "(4, CUDA, extern __shared__ int shared[];)"}
{"predict": "(6, TBB, tbb::filter<void, void> one_filter( filter_table[i], i_filter );)", "label": "(9, TBB, tbb::parallel_pipeline( n_tokens, one_filter, context... );); (5, TBB, tbb::filter<void, void> one_filter( filter_table[i], i_filter );)"}
{"predict": "(13, MPI, MPI_Bcast(dims, RANK, MPI_INT, 0, comm);); (2, MPI, MPI_Comm_rank(comm, &comm_rank);)", "label": "(13, MPI, MPI_Bcast(dims, 2, MPI_INT, 0, comm);); (2, MPI, MPI_Comm_rank(comm, &comm_rank);)"}
{"predict": "(6, MPI, MPI_Attr_get(comm, lkey[i], &val_p, &flag);)", "label": "(6, MPI, MPI_Comm_get_attr(comm, lkey[i], &val_p, &flag);)"}
{"predict": "(14, CUDA, double term = thrust::reduce(thrust::device, v_temp.begin(), v_temp.end(), 0.0, thrust::plus<double>());); (7, CUDA, thrust::device_vector<double> v_temp(n);); (5, CUDA, double* dv_ptr = thrust::raw_pointer_cast(v_temp.data());)", "label": "(14, CUDA, double term = thrust::reduce(thrust::device, v_temp.begin(), v_temp.end(), 0.0, thrust::plus<double>());); (7, CUDA, thrust::device_vector<double> v_temp(n);); (7, CUDA, double* dv_ptr = thrust::raw_pointer_cast(v_temp.data());)"}
{"predict": "(13, OpenMP, #pragma omp target); (1, OpenMP, #pragma omp parallel)", "label": "(13, OpenMP, printf(\"main parallel 2 from %d of %d\\n\", omp_get_thread_num(), omp_get_num_threads() );); (1, OpenMP, #pragma omp parallel); (2, OpenMP, printf(\"main parallel 1 from %d of %d\\n\", omp_get_thread_num(), omp_get_num_threads() );)"}
{"predict": "(8, OpenMP, const std::string comp_name(x.first);)", "label": "(8, OpenMP, const std::string comp_name(x.first);)"}
{"predict": "(2, OpenMP, #pragma omp target teams distribute parallel for simd)", "label": "(2, OpenMP, #pragma omp target teams distribute parallel for simd)"}
{"predict": "(8, CUDA, extern __shared__ int shist[];)", "label": "(3, CUDA, extern __shared__ int shist[];)"}
{"predict": "(20, CUDA, checkCudaErrors(cudaSetDevice(0));)", "label": "(20, CUDA, checkCudaErrors(cudaSetDevice(0));)"}
{"predict": "(65, OpenMP, #define OP_GOMP_CRITICAL_READ(OP, FLAG))", "label": "(65, OpenMP, #define OP_GOMP_CRITICAL_READ(OP, FLAG))"}
{"predict": "(19, OpenMP, #pragma omp target teams distribute parallel for simd if (parallel: false)); (10, OpenMP, #pragma omp target teams distribute parallel for simd if(simd: true) nontemporal(Arg))", "label": "(19, OpenMP, #pragma omp target teams distribute parallel for simd if (parallel: false)); (10, OpenMP, #pragma omp target teams distribute parallel for simd if(simd: true) nontemporal(Arg))"}
{"predict": "(3, CUDA, __shared__ typename Epilogue::Workspace shared_storage;)", "label": "(3, CUDA, __shared__ typename Epilogue::SharedStorage shared_storage;)"}
{"predict": "(17, CUDA, cudaMemsetAsync(nulls.data(), 0xcccc, nulls.size(), rmm::cuda_stream_default.value());)", "label": "(17, CUDA, cudaMemsetAsync(nulls.data(), 0xcccc, nulls.size(), rmm::cuda_stream_default.value());)"}
{"predict": "(13, CUDA, cudaError_t err = cudaFree(ptr);)", "label": "(13, CUDA, cudaError_t err = cudaFree(ptr);)"}
{"predict": "(10, OpenMP, __kmpc_omp_task(NULL, 0, task);); (2, OpenMP, printf(\"%d: creating task\\n\", omp_get_thread_num());)", "label": "(10, OpenMP, __kmpc_omp_task(NULL, 0, task);); (2, OpenMP, printf(\"%d: creating task\\n\", omp_get_thread_num());)"}
{"predict": "(2, MPI, MPIDataCommunicator mpi_world_communicator(MPI_COMM_WORLD);)", "label": "(2, MPI, MPIDataCommunicator mpi_world_communicator(MPI_COMM_WORLD);)"}
{"predict": "(7, OpenMP, #pragma omp simd private(myind, g_ind), linear(ind), aligned(arr), linear(uval(ref)))", "label": "(7, OpenMP, #pragma omp simd private(myind, g_ind), linear(ind), aligned(arr), linear(uval(ref)))"}
{"predict": "(32, CUDA, CUDA_CHECK(cudaStreamSynchronize(stream));); (34, CUDA, CUDA_CHECK(cudaFree(d_data));)", "label": "(32, CUDA, CUDA_CHECK(cudaStreamSynchronize(stream));); (34, CUDA, CUDA_CHECK(cudaFree(d_data));)"}
{"predict": "(5, CUDA, __shared__ uint s_Hist[HISTOGRAM256_THREADBLOCK_SIZE * WARP_COUNT];)", "label": "(5, CUDA, __shared__ uint s_Hist[HISTOGRAM256_THREADBLOCK_MEMORY];)"}
{"predict": "(17, OpenMP, #pragma omp target teams distribute parallel for reduction(+:sum))", "label": "(17, OpenMP, #pragma omp parallel for default(shared) private(i))"}
{"predict": "(35, CUDA, cudaFree(res_dev);); (28, CUDA, cudaMalloc(&res_dev, sizeof(float));); (30, CUDA, cudaMemcpy(&res_host, res_dev, sizeof(float), cudaMemcpyDeviceToHost);)", "label": "(35, CUDA, cudaFree(res_dev);); (28, CUDA, cudaMalloc(&res_dev, sizeof(float));); (30, CUDA, cudaMemcpy(&res_host, res_dev, sizeof(float), cudaMemcpyDeviceToHost);)"}
{"predict": "(1, CUDA, if (!IsGoogleCudaEnabled()) return;)", "label": "(1, CUDA, if (!IsGoogleCudaEnabled()) return;)"}
{"predict": "(3, CUDA, extern __shared__ unsigned scx1[];)", "label": "(3, CUDA, extern __shared__ unsigned scx1[];)"}
{"predict": "(22, CUDA, return writeAccessPolicyWindowToJava(env, nativeObject.accessPolicyWindow, javaWindow);)", "label": "(21, CUDA, setCudaAccessPolicyWindow(env, javaObject, nativeObject.accessPolicyWindow);)"}
{"predict": "(22, CUDA, fptype ret = thrust::norm(totalAmp);)", "label": "(22, CUDA, fptype ret = thrust::norm(totalAmp);)"}
{"predict": "(6, OpenMP, #pragma omp parallel for)", "label": "(6, OpenMP, #pragma omp parallel for)"}
{"predict": "(15, OpenCL, retVal = clEnqueueUnmapMemObject(cmdQ.get(), image.get(), mappedPtr, 0, nullptr, nullptr);); (7, OpenCL, void *mappedPtr = clEnqueueMapImage(cmdQ.get(), image.get(), CL_TRUE, CL_MAP_WRITE, &origin[0], &region[0], nullptr, nullptr, 0, nullptr, nullptr, &retVal);)", "label": "(8, OpenCL, void *mappedPtr = clEnqueueMapImage(cmdQ.get(), image.get(), CL_TRUE, CL_MAP_WRITE, &origin[0], &region[0], nullptr, nullptr, 0, nullptr, nullptr, &retVal);); (14, OpenCL, retVal = clEnqueueUnmapMemObject(cmdQ.get(), image.get(), mappedPtr, 0, nullptr, nullptr);)"}
{"predict": "(8, CUDA, auto err = thrust::mismatch(d_reference_begin, d_reference_end, d_data);); (2, CUDA, thrust::copy(host_reference, host_reference + num_items, d_tmp_buffer);); (7, CUDA, size_t index = thrust::distance(d_reference_begin, err.first);)", "label": "(7, CUDA, auto err = thrust::mismatch(thrust::device, d_reference_begin, d_reference_end, d_data);); (2, CUDA, CubDebugExit(cudaMemcpy(d_tmp_buffer, host_reference, sizeof(T) * num_items, cudaMemcpyHostToDevice));); (9, CUDA, const auto index = thrust::distance(d_reference_begin, err.first);)"}
{"predict": "(12, CUDA, CUDA_SAFE_CALL(cudaMalloc(&device_buffer, buffer_size * sizeof(value_type)));)", "label": "(12, CUDA, CUDA_SAFE_CALL(cudaMalloc(&device_buffer, buffer_size * sizeof(value_type)));)"}
{"predict": "(3, CUDA, __shared__ float local[threads];)", "label": "(3, CUDA, __shared__ float local[threads];)"}
{"predict": "(22, OpenCL, clReleaseEvent(outEvent1);)", "label": "(22, OpenCL, clReleaseEvent(outEvent1);)"}
{"predict": "(6, CUDA, extern __shared__ uint64_t s_QHatModp[];)", "label": "(6, CUDA, extern __shared__ uint64_t s_QHatModp[];)"}
{"predict": "(10, MPI, MPI_Allreduce(input, output, 1, dtcmp_get_uint64t_min_max_sum_dtype(), MPI_SUM, comm);)", "label": "(10, MPI, MPI_Allreduce(input, output, 1, dtcmp_type_3uint64t, dtcmp_reduceop_mms_3uint64t, comm);)"}
{"predict": "(2, OpenMP, omp_autotune(self, OMP_SCALE);)", "label": "(2, OpenMP, omp_autotune(self, OMP_SCALE);)"}
{"predict": "(2, MPI, MPIDataCommunicator mpi_world_communicator(MPI_COMM_WORLD);)", "label": "(2, MPI, MPIDataCommunicator mpi_world_communicator(MPI_COMM_WORLD);)"}
{"predict": "(25, MPI, MPI_Send(lnzval, len2, MPI_DOUBLE, receiver, k, grid3d->zscp.comm);)", "label": "(25, MPI, MPI_Send(lnzval, len2, MPI_DOUBLE, receiver, k, grid3d->zscp.comm);)"}
{"predict": "(2, OpenMP, #pragma omp for schedule(dynamic))", "label": "(2, OpenMP, #pragma omp for schedule(nonmonotonic: dynamic))"}
{"predict": "(21, MPI, MPI_Abort(MPI_COMM_WORLD, 1);)", "label": "(21, MPI, MPI_Abort(MPI_COMM_WORLD, 1);)"}
{"predict": "(5, OpenMP, #pragma omp target enter data map(to:a[:N])); (21, OpenMP, #pragma omp target exit data map(from:a[:N])); (5, OpenMP, #pragma omp target map(to:b[:N]))", "label": "(5, OpenMP, #pragma omp target enter data map(to:a[:N]))"}
{"predict": "(15, TBB, test_basic<MyCheckedStateSet>(\"concurrent unordered set (checked state of elements)\", tbb::internal::true_type());)", "label": "(15, TBB, test_basic<MyCheckedStateSet>(\"concurrent unordered set (checked element state)\", tbb::internal::true_type());)"}
{"predict": "(9, CUDA, factory = *internal::MakeCUDAExecutorImplementation();)", "label": "(9, CUDA, factory = *internal::MakeCUDAExecutorImplementation();)"}
{"predict": "(25, CUDA, cudaDeviceSynchronize();)", "label": "(25, CUDA, cudaDeviceSynchronize();)"}
{"predict": "(15, CUDA, checkCudaRuntime(cudaMemcpyAsync(image_device, image_host, size_image, cudaMemcpyHostToDevice, stream));)", "label": "(15, CUDA, checkCudaRuntime(cudaMemcpyAsync(image_device, image_host, size_image, cudaMemcpyHostToDevice, stream));)"}
{"predict": "(8, SYCL, return hipsycl::libkernel::sscp::work_group_broadcast<__acpp_##input_type>(sender, x, shrd_x);)", "label": "(8, SYCL, return hipsycl::libkernel::sscp::wg_broadcast(sender, x, shrd_x);)"}
{"predict": "(38, CUDA, cudaFree(res_dev);); (31, CUDA, cudaMalloc(&res_dev, sizeof(float));); (33, CUDA, cudaMemcpy(&res_host, res_dev, sizeof(float), cudaMemcpyDeviceToHost);)", "label": "(38, CUDA, cudaFree(res_dev);); (31, CUDA, cudaMalloc(&res_dev, sizeof(float));); (33, CUDA, cudaMemcpy(&res_host, res_dev, sizeof(float), cudaMemcpyDeviceToHost);)"}
{"predict": "(19, CUDA, checkCudaErrors(cudaGetLastError());); (17, CUDA, checkCudaErrors(cudaStreamSynchronize(stream));)", "label": "(18, CUDA, checkCudaErrors(cudaDeviceSynchronize());); (18, CUDA, checkCudaErrors(cudaGetLastError());)"}
{"predict": "(2, SYCL, sycl::queue q = get_queue();); (2, SYCL, int* data = sycl::malloc_shared<int>(1024, q);); (2, SYCL, const int* table = sycl::malloc_shared<int>(4, q);); (2, SYCL, sycl::free(table, q);); (4, SYCL, sycl::free(data, q);)", "label": "(2, SYCL, sycl::queue q = get_queue();); (3, SYCL, int* data = sycl::malloc_device<int>(1024, q);)"}
{"predict": "(48, OpenMP, #pragma omp sections); (3, OpenMP, #pragma omp section); (48, OpenMP, #pragma omp cancellation point sections); (44, OpenMP, #pragma omp cancel sections)", "label": "(4, OpenMP, #pragma omp sections); (49, OpenMP, #pragma omp sections nowait); (28, OpenMP, #pragma omp section)"}
{"predict": "(36, CUDA, CUDA_CHECK(cudaStreamSynchronize(stream));); (38, CUDA, CUDA_CHECK(cudaFree(d_data));)", "label": "(36, CUDA, CUDA_CHECK(cudaStreamSynchronize(stream));); (38, CUDA, CUDA_CHECK(cudaFree(d_data));)"}
{"predict": "(1, CUDA, cudaFree(0);)", "label": "(5, CUDA, c.CUDAConfig().device_id = 0;)"}
{"predict": "(7, CUDA, fcuda::Check_CudaErroorFun(\"DgReduSumUint\");); (5, CUDA, cudaMemcpy(data,datag+inidata,sizeof(unsigned)*ndata,cudaMemcpyDeviceToHost);)", "label": "(7, CUDA, fcuda::Check_CudaErroorFun(\"DgReduSumUint\");); (5, CUDA, cudaMemcpy(data,datag+inidata,sizeof(unsigned)*ndata,cudaMemcpyDeviceToHost);)"}
{"predict": "(14, OpenMP, #pragma omp parallel); (14, OpenMP, #pragma omp task if (task: false))", "label": "(14, OpenMP, #pragma omp parallel); (14, OpenMP, #pragma omp task if (task: false))"}
{"predict": "(18, CUDA, getLastCudaError(\"mergeElementaryIntervalsKernel<0> failed\\n\");); (12, CUDA, getLastCudaError(\"mergeElementaryIntervalsKernel<1> failed\\n\");)", "label": "(13, CUDA, getLastCudaError(\"mergeElementaryIntervalsKernel<1> failed\\n\");); (17, CUDA, getLastCudaError(\"mergeElementaryIntervalsKernel<0> failed\\n\");)"}
{"predict": "(14, CUDA, fprintf(stderr, \"CUDA kernel failed : %s\\n\", cudaGetErrorString(err));); (11, CUDA, err = cudaGetLastError();)", "label": "(14, CUDA, fprintf(stderr, \"CUDA kernel failed : %s\\n\", cudaGetErrorString(err));); (11, CUDA, err = cudaGetLastError();)"}
{"predict": "(4, CUDA, CudaCheckError();)", "label": "(4, CUDA, CudaCheckError();)"}
{"predict": "(343, CUDA, __shared__ int cur_send_num;); (341, CUDA, __shared__ int recv_num, finish_num;)", "label": "(343, CUDA, __shared__ int cur_send_num;); (341, CUDA, __shared__ int recv_num, finish_num;)"}
{"predict": "(6, MPI, MPI_Comm_size(comm, &nproc);); (4, MPI, MPI_Comm_rank(comm, &rank);)", "label": "(6, MPI, MPI_Comm_size(comm, &nproc);); (4, MPI, MPI_Comm_rank(comm, &rank);)"}
{"predict": "(7, MPI, MPI_Comm_size(MPI_COMM_WORLD, &world_size);); (18, MPI, MPI_Bcast(&nccl_id, sizeof(nccl_id), MPI_BYTE, 0, MPI_COMM_WORLD);); (4, MPI, MPI_Comm_rank(MPI_COMM_WORLD, &rank);); (11, MPI, MPI_Barrier(MPI_COMM_WORLD);); (3, MPI, MPI_Init(NULL, NULL);)", "label": "(6, MPI, MPI_CHECK(MPI_Init(NULL, NULL));); (15, MPI, MPI_CHECK(MPI_Bcast((void *)&nccl_id, sizeof(nccl_id), MPI_BYTE, 0, MPI_COMM_WORLD));); (16, CUDA, cudaSetDevice(rank);)"}
{"predict": "(14, CUDA, thrust::device_vector<Element> d_src = h_src;); (8, CUDA, thrust::host_vector<Element> h_src(kNumel);)", "label": "(14, CUDA, thrust::device_vector<Element> d_src = h_src;); (8, CUDA, thrust::host_vector<Element> h_src(kNumel);)"}
{"predict": "(51, CUDA, cudaFree(res_dev);); (44, CUDA, cudaMalloc(&res_dev, sizeof(float));); (46, CUDA, cudaMemcpy(&res_host, res_dev, sizeof(float), cudaMemcpyDeviceToHost);)", "label": "(51, CUDA, cudaFree(res_dev);); (44, CUDA, cudaMalloc(&res_dev, sizeof(float));); (46, CUDA, cudaMemcpy(&res_host, res_dev, sizeof(float), cudaMemcpyDeviceToHost);)"}
{"predict": "(187, OpenMP, comp_add_script_line(\"Flag=MGF_REMOVE_NONPRINTABLE\\n\");); (175, OpenMP, comp_add_script_line(\"Flag=MGF_ADD_TRAILING_NULL\\n\");); (182, OpenMP, comp_add_script_line(\"Flag=MGF_REMOVE_NULLS\\n\");); (196, OpenMP, comp_add_script_line(\"Flag=MGF_FIX_LENGTH16\\n\");); (189, OpenMP, comp_add_script_line(\"Flag=MGF_FIX_LENGTH24\\n\");); (193, OpenMP, comp_add_script_line(\"Flag=MGF_FIX_LENGTH32\\n\");); (178, OpenMP, comp_add_script_line(\"Flag=MGF_REMOVE_LEADING_NULLS\\n\");); (71, OpenMP, comp_add_script_line(\"Flag=MGF_USERNAME\\n\");); (183, OpenMP, comp_add_script_line(\"Flag=MGF_REPLACE_NULLS\\n\");); (115, OpenMP, comp_add_script_line(\"Flag=MGF_PASSWORD\\n\");)", "label": "(31, OpenMP, comp_add_script_line(\"Flag=MGF_SALT_AS_HEX_%s\\n\", tmp);); (19, OpenMP, comp_do_parse(0, nSyms-1);); (222, OpenMP, comp_add_script_line(\"Func=DynamicFunc__append_keys_pad20\\n\"); if (use_inp1) len_comp += 20; else len_comp2 += 20; }); (58, OpenMP, if (bNeedS) comp_add_script_line(\"Flag=MGF_SALTED\\n\");); (153, OpenMP, comp_add_script_line(\"Func=DynamicFunc__LargeHash_OUTMode_raw\\n\");); (18, OpenMP, comp_add_script_line(\"Expression=dynamic=%s\\n\", p->pExpr);); (306, OpenMP, comp_add_script_line(\"Flag=MGF_INPBASE64b\\n\");); (307, OpenMP, comp_add_script_line(\"Flag=MGF_INPBASE64m\\n\");); (186, OpenMP,"}
{"predict": "(6, CUDA, __shared__ int s_data[32][32];)", "label": "(6, CUDA, __shared__ int s_data[32][33];)"}
{"predict": "(6, CUDA, st = cudaMalloc(&test_ptr, ucc_mc_cuda_config->mpool_elem_size);); (12, CUDA, cudaFree(test_ptr);)", "label": "(6, CUDA, st = cudaMalloc(&test_ptr, TEST_ALLOC_SIZE);); (11, CUDA, cudaFree(test_ptr);)"}
{"predict": "(8, OpenMP, #pragma omp section); (6, OpenMP, #pragma omp parallel)", "label": "(8, OpenMP, #pragma omp section); (6, OpenMP, #pragma omp parallel)"}
{"predict": "(2, OpenMP, #pragma omp target enter data map(to : c[0 : size])); (28, OpenMP, #pragma omp target exit data map(delete : c[0 : size])); (19, OpenMP, runbench_range<0, 1, 2, 3, 4, 6, 8, 12, 16, 20, 24, 28, 32, 40, 6 * 8, 7 *(20, OpenMP, #pragma omp target); (19, OpenMP, runbench_warmup(c, size);)", "label": "(2, OpenMP, #pragma omp parallel for schedule(static))"}
{"predict": "(12, TBB, tbb::parallel_sort(iter, iter + n, *compare );)", "label": "(12, TBB, tbb::parallel_sort(iter, iter + n, *compare );)"}
{"predict": "(3, CUDA, HANDLE_ERROR(cudaStreamCreate(&stream));); (15, CUDA, HANDLE_ERROR(cudaStreamDestroy(stream));)", "label": "(4, CUDA, HANDLE_ERROR(cudaStreamCreate(&stream));); (15, CUDA, HANDLE_ERROR(cudaStreamDestroy(stream));)"}
{"predict": "(5, CUDA, __shared__ uint data[MERGE_THREADBLOCK_SIZE];)", "label": "(12, CUDA, __shared__ uint data[MERGE_THREADBLOCK_SIZE];)"}
{"predict": "(2, OpenMP, #pragma omp critical)", "label": "(2, OpenMP, #pragma omp critical)"}
{"predict": "(19, MPI, MPI_Comm_rank(comm, &rank);)", "label": "(19, MPI, MPI_Comm_rank(comm, &rank);)"}
{"predict": "(3, OpenMP, #pragma omp target map(tofrom: threadCount)); (4, OpenMP, #pragma omp metadirective)", "label": "(3, OpenMP, #pragma omp target map(tofrom: threadCount)); (4, OpenMP, #pragma omp metadirective)"}
{"predict": "(2, CUDA, __shared__ typename BlockReduce<float>::TempStorage m_storage;); (2, CUDA, __shared__ typename BlockReduce<float>::TempStorage v_storage;)", "label": "(2, CUDA, __shared__ typename BlockReduce<float>::TempStorage v_storage;); (0, CUDA, __shared__ typename BlockReduce<float>::TempStorage m_storage;)"}
{"predict": "(6, MPI, MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);); (4, MPI, MPI_Comm_size(MPI_COMM_WORLD, &world_size);)", "label": "(6, MPI, MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);); (4, MPI, MPI_Comm_size(MPI_COMM_WORLD, &world_size);)"}
{"predict": "(8, OpenMP, rec = get_decomp_record(code);)", "label": "(8, OpenMP, rec = get_decomp_record(code);)"}
{"predict": "(9, OpenCL, plan->kernel = clCreateKernel(program, kernel_info->name, &err);)", "label": "(9, OpenCL, kernel_info->kernel = clCreateKernel(program, kernel_info->kernel_name, &err);)"}
{"predict": "(8, TBB, tbb::task_scheduler_init init_market_p_plus_one(MaxThread + 1);); (7, TBB, tbb::task_scheduler_init init_market_p_plus_two(MaxThread + 2);)", "label": "(8, TBB, tbb::task_scheduler_init init_market_p_plus_one(MaxThread + 1);)"}
{"predict": "(1, TBB, oneapi::tbb::flow::graph g;)", "label": "(1, TBB, oneapi::tbb::flow::graph g;)"}
{"predict": "(1, OpenMP, #pragma omp parallel num_threads(1)); (6, OpenMP, #pragma omp cancel parallel); (1, OpenMP, #pragma omp master)", "label": "(1, OpenMP, #pragma omp parallel num_threads(2)); (10, OpenMP, #pragma omp cancellation point parallel); (3, OpenMP, #pragma omp cancel parallel)"}
{"predict": "(8, CUDA, __shared__ double sum[128];)", "label": "(8, CUDA, __shared__ double sum[block_size];)"}
{"predict": "(21, OpenCL, retVal = clReleaseMemObject(smallBuffer);); (4, OpenCL, cl_mem smallBuffer = clCreateBuffer(clContext, flags, size, hostPtr, &retVal);); (24, OpenCL, EXPECT_EQ(clReleaseContext(context), CL_SUCCESS);)", "label": "(21, OpenCL, retVal = clReleaseMemObject(smallBuffer);); (5, OpenCL, cl_mem smallBuffer = clCreateBuffer(clContext, flags, size, hostPtr, &retVal);); (24, OpenCL, EXPECT_EQ(clReleaseContext(context), CL_SUCCESS);)"}
{"predict": "(13, CUDA, cudaCheck(cudaDeviceSynchronize());); (13, CUDA, cudaCheck(cudaGetLastError());)", "label": "(13, CUDA, cudaCheck(cudaGetLastError());)"}
{"predict": "(16, CUDA, CUDASimulation cudaSimulation(model);)", "label": "(16, CUDA, CUDASimulation cudaSimulation(model);)"}
{"predict": "(4, CUDA, HANDLE_ERROR(cudaGetDeviceProperties(&prop, whichDevice));); (2, CUDA, HANDLE_ERROR(cudaGetDevice(&whichDevice));)", "label": "(4, CUDA, checkCudaErrors(cudaGetDeviceProperties(&prop, whichDevice));); (2, CUDA, checkCudaErrors(cudaGetDevice(&whichDevice));)"}
{"predict": "(12, OpenCL, status = clEnqueueNDRangeKernel(pCmdQ, mockKernel.mockMultiDeviceKernel, testedWorkDim, nullptr, globalWorkSize, localWorkSize, 0, nullptr, nullptr);)", "label": "(12, OpenCL, status = clEnqueueNDRangeKernel(pCmdQ, mockKernel.mockMultiDeviceKernel, testedWorkDim, nullptr, globalWorkSize, localWorkSize, 0, nullptr, nullptr);)"}
{"predict": "(23, CUDA, CSC(cudaGetLastError(), STATUS_FAILURE);)", "label": "(23, CUDA, CSC(cudaGetLastError(), STATUS_FAILURE);)"}
{"predict": "(42, CUDA, cudaFree(res_dev);); (35, CUDA, cudaMalloc(&res_dev, sizeof(float));); (37, CUDA, cudaMemcpy(&res_host, res_dev, sizeof(float), cudaMemcpyDeviceToHost);)", "label": "(42, CUDA, cudaFree(res_dev);); (35, CUDA, cudaMalloc(&res_dev, sizeof(float));); (37, CUDA, cudaMemcpy(&res_host, res_dev, sizeof(float), cudaMemcpyDeviceToHost);)"}
{"predict": "(11, CUDA, extern __shared__ __align__(sizeof(double)) unsigned char buf_[];)", "label": "(11, CUDA, extern __shared__ __align__(sizeof(double)) unsigned char buf_[];)"}
{"predict": "(44, MPI, MPI_T_finalize();); (20, MPI, MPI_T_init_thread(required, &provided);)", "label": "(44, MPI, MPI_T_finalize();); (19, MPI, MPI_T_init_thread(required, &provided);)"}
{"predict": "(10, MPI, MPI_Comm c_comm = MPI_Comm_f2c(*comm);)", "label": "(10, MPI, MPI_Comm c_comm = MPI_Comm_f2c(*comm);)"}
{"predict": "(6, MPI, MPI_Type_get_attr(type, key[i], &val_p, &flag);)", "label": "(6, MPI, MPI_Type_get_attr(type, key[i], &val_p, &flag);)"}
{"predict": "(7, OpenMP, #pragma omp parallel)", "label": "(7, OpenMP, #pragma omp for nowait schedule(runtime))"}
{"predict": "(5, OpenMP, #pragma omp parallel for)", "label": "(5, OpenMP, #pragma omp parallel for)"}
{"predict": "(13, MPI, MPI_Ireduce_scatter_block_c(sendbuf, recvbuf, count, datatype, MPI_SUM, comm, &req);); (9, MPI, MPI_Reduce_scatter_block_c(sendbuf, recvbuf, count, datatype, MPI_SUM, comm);); (12, MPI, MPI_Wait(&req, MPI_STATUS_IGNORE);)", "label": "(14, MPI, MPI_Wait(&req, MPI_STATUS_IGNORE);); (12, MPI, MPI_Ireduce_scatter_block_c(sendbuf, recvbuf, count, datatype, MPI_SUM, comm, &req);); (8, MPI, MPI_Reduce_scatter_block_c(sendbuf, recvbuf, count, datatype, MPI_SUM, comm);)"}
{"predict": "(44, OpenCL, clReleaseEvent(retEvent);)", "label": "(44, OpenCL, clReleaseEvent(retEvent);)"}
{"predict": "(85, CUDA, cudaFuncGetAttributes(&cuattr, slsum_fmod_inv_gpu_mrhs_nvshmem);); (88, CUDA, cudaOccupancyMaxPotentialBlockSize(&minGridSize,&myblockSize,(const void *) swait_bcrd ,0,0 );); (140, CUDA, CUDA_CHECK(cudaDeviceSynchronize());); (83, CUDA, cudaDeviceSetLimit(cudaLimitStackSize, cuattr.localSizeBytes);); (76, CUDA, cudaStreamCreateWithFlags(&stream[i], cudaStreamNonBlocking);); (134, CUDA, CUDA_CHECK(cudaGetLastError());); (138, CUDA, CUDA_CHECK(cudaStreamDestroy(stream[i]));)", "label": "(85, CUDA, cudaDeviceSetLimit(cudaLimitStackSize, cuattr.localSizeBytes);); (140, CUDA, CUDA_CHECK(cudaDeviceSynchronize());); (78, CUDA, cudaStreamCreateWithFlags(&stream[i], cudaStreamNonBlocking);); (135, CUDA, CUDA_CHECK(cudaGetLastError());); (80, CUDA, cudaFuncGetAttributes(&cuattr, slsum_fmod_inv_gpu_mrhs_nvshmem);); (138, CUDA, CUDA_CHECK(cudaStreamDestroy(stream[i]));); (82, CUDA, cudaOccupancyMaxPotentialBlockSize(&minGridSize,&myblockSize,(const void *) swait_bcrd ,0,0 );)"}
{"predict": "(2, CUDA, extern __shared__ unsigned int s_data[];); (0, CUDA, extern __device__ unsigned int d_data[];)", "label": "(2, CUDA, __shared__ volatile unsigned int s_data[WARP_SIZE*2];)"}
{"predict": "(4, TBB, using MyVector = oneapi::tbb::concurrent_vector<move_support_tests::Foo, MyAllocator>;)", "label": "(4, TBB, using MyVector = oneapi::tbb::concurrent_vector<move_support_tests::Foo, MyAllocator>;); (8, TBB, oneapi::tbb::parallel_for(oneapi::tbb::blocked_range<std::size_t>(0, 10000*s, s), GrowToAtLeast<MyVector>(use_two_arg_form, v, copy_from), oneapi::tbb::simple_partitioner());)"}
{"predict": "(31, OpenCL, clReleaseMemObject(buffer);)", "label": "(31, OpenCL, clReleaseMemObject(buffer);)"}
{"predict": "(11, TBB, tbb::tick_count t1 = tbb::tick_count::now();); (10, TBB, tbb::parallel_for(tbb::blocked_range<size_t>(0,n,n/10),AddOne<Counter<M> >(counter));)", "label": "(5, TBB, tbb::profiling::set_name(counter.mutex, name);); (11, TBB, tbb::parallel_for(tbb::blocked_range<size_t>(0,n,n/10),AddOne<Counter<M> >(counter));); (11, TBB, tbb::tick_count t1 = tbb::tick_count::now();)"}
{"predict": "(6, OpenMP, #pragma omp parallel for firstprivate(length))", "label": "(6, OpenMP, #pragma omp parallel for firstprivate(length, v_cut))"}
{"predict": "(33, OpenMP, #pragma omp parallel if(Gc>0.0 && c>0 && Sc>0.0)); (5, OpenMP, #pragma omp parallel); (23, OpenMP, #pragma omp target if(Ga>0.0 && a>0 && Sa>0.0))", "label": "(32, OpenMP, #pragma omp parallel if(Gc>0.0 && c>0 && Sc>0.0)); (22, OpenMP, #pragma omp target if(Ga>0.0 && a>0 && Sa>0.0))"}
{"predict": "(7, CUDA, __shared__ block_radix_sort_t::TempStorage temp_storage;)", "label": "(7, CUDA, __shared__ block_radix_sort_t::TempStorage temp_storage;)"}
{"predict": "(18, OpenMP, #pragma omp target teams distribute if(cond) firstprivate(fp) reduction(+:rd) map(alloc:map))", "label": "(18, OpenMP, #pragma omp target teams distribute if(cond) firstprivate(fp) reduction(+:rd) map(alloc:map))"}
{"predict": "(12, CUDA, cudaMemsetAsync(d_sums, 0, nkeys * sizeof(Type), stream);)", "label": "(12, CUDA, cudaMemset(d_sums, 0, sizeof(Type) * nkeys * ncols);)"}
{"predict": "(39, CUDA, return cudaGetLastError();)", "label": "(39, CUDA, return cudaGetLastError();)"}
{"predict": "(19, MPI, MPI_Reduce_local(outbuf, (char*)outbuf - sizeof(type), 1, type, op);)", "label": "(19, MPI, MPI_Reduce_local((void*)inbuf, outbuf, count, type, op);)"}
{"predict": "(12, CUDA, cudaMemcpy(pointers, cpuPointers, sizeof(uint8_t*) * part, cudaMemcpyHostToDevice);); (6, CUDA, uint8_t ** pointers = (uint8_t**)FastllmCudaMalloc(sizeof(uint8_t*) * part);); (14, CUDA, FastllmCudaFree(pointers);)", "label": "(16, CUDA, FastllmCudaFree(pointers);); (12, CUDA, cudaMemcpy(pointers, cpuPointers, sizeof(uint8_t*) * part, cudaMemcpyHostToDevice);); (6, CUDA, uint8_t ** pointers = (uint8_t**)FastllmCudaMalloc(sizeof(uint8_t*) * part);)"}
{"predict": "(24, CUDA, CHECK_CUDA_RETURN(cudaGetLastError());)", "label": "(24, CUDA, CHECK_CUDA_RETURN(cudaGetLastError());)"}
{"predict": "(19, OpenCL, clReleaseContext_ExpectAndReturn(make_context(0), CL_SUCCESS);)", "label": "(19, OpenCL, clReleaseContext_ExpectAndReturn(make_context(0), CL_SUCCESS);)"}
{"predict": "(119, OpenMP, #pragma omp task); (107, OpenMP, #pragma omp taskgroup)", "label": "(101, OpenMP, #pragma omp task); (102, OpenMP, #pragma omp taskgroup)"}
{"predict": "(17, CUDA, qmc_cuda::cuda_check(cudaDeviceSynchronize());); (15, CUDA, qmc_cuda::cuda_check(cudaGetLastError());)", "label": "(17, CUDA, qmc_cuda::cuda_check(cudaDeviceSynchronize());); (15, CUDA, qmc_cuda::cuda_check(cudaGetLastError());)"}
{"predict": "(27, MPI, MPI_Allreduce(&local, &global, 1, MPI_INT, MPI_SUM, MPI_COMM_WORLD);); (10, MPI, MPI_Get_processor_name(mach_name, &mach_len);); (28, MPI, MPI_Finalize();)", "label": "(28, MPI, MPI_Finalize();); (8, MPI, MPI_Get_processor_name(mach_name,&mach_len);); (22, MPI, MPI_Allreduce(&local,&global,1,MPI_INT,MPI_SUM,MPI_COMM_WORLD);)"}
{"predict": "(19, OpenCL, clReleaseEvent(event);)", "label": "(19, OpenCL, clReleaseEvent(event);)"}
{"predict": "(8, OpenMP, #pragma omp master taskloop firstprivate(t_var, vec, s_arr, s_arr, var, var))", "label": "(8, OpenMP, #pragma omp master taskloop lastprivate(t_var, vec, s_arr, s_arr, var, var))"}
{"predict": "(11, OpenMP, #pragma omp target teams distribute parallel for map(tofrom : a[ : n]) map(to : b[ : n]))", "label": "(11, OpenMP, #pragma omp target teams distribute parallel for map(tofrom : a[ : n]) map(to : b[ : n]))"}
{"predict": "(8, OpenMP, #pragma omp target update CLAUSE(present: i)); (6, OpenMP, #pragma omp target data map(alloc: i))", "label": "(8, OpenMP, #pragma omp target update CLAUSE(present: i)); (6, OpenMP, #pragma omp target enter data map(alloc: i)); (7, OpenMP, #pragma omp target exit data map(delete: i))"}
{"predict": "(123, OpenMP, #pragma omp for simd collapse(3))", "label": "(163, OpenMP, #pragma omp for collapse(2))"}
{"predict": "(4, OpenCL, clCreateContext_StubWithCallback(clCreateContext_testContextWithDevicesNonNullProperties);)", "label": "(5, OpenCL, clReleaseContext_ExpectAndReturn(make_context(0), CL_SUCCESS);); (3, OpenCL, clCreateContext_StubWithCallback(clCreateContext_testContextNonNullProperties);)"}
{"predict": "(7, OpenACC, #pragma acc loop gang worker vector); (5, OpenACC, #pragma acc parallel deviceptr(position,cell_keys))", "label": "(7, OpenACC, #pragma acc loop gang worker vector); (5, OpenACC, #pragma acc parallel deviceptr(position,cell_keys))"}
{"predict": "(8, OpenMP, #pragma omp parallel for)", "label": "(5, OpenMP, #pragma omp workshare)"}
{"predict": "(6, OpenCL, retVal = clEnqueueMemcpyINTEL(this->pCmdQ, true, unifiedMemoryPtr, input.data(), dataSize, 0, nullptr, nullptr);)", "label": "(6, OpenCL, retVal = clEnqueueMemcpyINTEL(this->pCmdQ, true, unifiedMemoryPtr, input.data(), dataSize, 0, nullptr, nullptr);)"}
{"predict": "(1, OpenMP, void *p = omp_alloc(1024 * 1024, default_alloc);); (11, OpenMP, omp_free(p, default_alloc);)", "label": "(1, OpenMP, omp_allocator_handle_t default_alloc = omp_get_default_allocator();); (4, OpenMP, int *p = (int *)omp_alloc(123456*sizeof(int));)"}
{"predict": "(11, OpenMP, #pragma omp for simd reduction(inscan, +:a[:n], b)); (44, OpenMP, #pragma omp scan inclusive(a[:n], b)); (192, OpenMP, #pragma omp scan exclusive(a[:n], b))", "label": "(194, OpenMP, #pragma omp scan exclusive(a[:n], b)); (44, OpenMP, #pragma omp scan inclusive(a[:n], b)); (9, OpenMP, #pragma omp for reduction(inscan, +:a[:n], b))"}
{"predict": "(17, OpenMP, volatile  int_t thread_id = omp_get_thread_num();)", "label": "(17, OpenMP, volatile  int_t thread_id = omp_get_thread_num();)"}
{"predict": "(14, OpenMP, #pragma omp target parallel for)", "label": "(14, OpenMP, #pragma omp target parallel for)"}
{"predict": "(16, MPI, MPI_Comm_rank(MPI_COMM_WORLD, &scr_rank);)", "label": "(16, MPI, MPI_Comm_rank(MPI_COMM_WORLD, &scri_rank);); (16, MPI, MPI_Comm_size(MPI_COMM_WORLD, &scri_ranks);)"}
{"predict": "(36, MPI, MPI_File_close(&c_info->fh);)", "label": "(36, MPI, MPI_File_close(&c_info->fh);)"}
{"predict": "(32, CUDA, CUDA_CHECK(cudaStreamSynchronize(stream));); (34, CUDA, CUDA_CHECK(cudaFree(d_data));)", "label": "(32, CUDA, CUDA_CHECK(cudaStreamSynchronize(stream));); (34, CUDA, CUDA_CHECK(cudaFree(d_data));)"}
{"predict": "(7, SYCL, sycl::accessor a(A, cgh, sycl::write_only, sycl::noinit);); (16, SYCL, sycl::accessor b(B, cgh, sycl::write_only, sycl::noinit);)", "label": "(16, SYCL, auto b = B.get_access<sycl::access_mode::write>(cgh);); (5, SYCL, auto a = A.get_access<sycl::access_mode::write>(cgh);)"}
{"predict": "(17, CUDA, CUDA_CHECK(cudaMalloc((void**)&d_mergedGroupStartID, sizeBytes));); (13, CUDA, CUDA_CHECK(cudaMalloc(&d_mergedGroupStartID, sizeBytes));); (8, CUDA, CUDA_CHECK(cudaDeclareConst(d_mergedGroupStartID, sizeBytes));)", "label": "(14, CUDA, os << \"__device__ \";); (8, CUDA, os << \"__device__ __constant__ \";)"}
{"predict": "(12, OpenMP, #pragma omp target teams distribute parallel for map(tofrom: data))", "label": "(12, OpenMP, #pragma omp target teams distribute parallel for)"}
{"predict": "(41, CUDA, cudaDeviceSynchronize();)", "label": "(41, CUDA, cudaDeviceSynchronize();)"}
{"predict": "(21, CUDA, cudaMemcpy(&max, tempCfl, sizeof(float), cudaMemcpyDeviceToHost);)", "label": "(21, CUDA, CUDA_SAFE_CALL(cudaMemcpy(&max, tempCfl, sizeof(float), cudaMemcpyDeviceToHost));)"}
{"predict": "(4, CUDA, auto input = thrust::device_vector<T>(d_input);)", "label": "(8, CUDA, auto input   = thrust::host_vector<coordinate<T>>(d_input);)"}
{"predict": "(20, CUDA, cudaFree(res_dev);); (10, CUDA, cudaMalloc(&res_dev, sizeof(float));); (12, CUDA, cudaMemcpy(&res_host, res_dev, sizeof(float), cudaMemcpyDeviceToHost);)", "label": "(20, CUDA, cudaFree(res_dev);); (10, CUDA, cudaMalloc(&res_dev, sizeof(float));); (12, CUDA, cudaMemcpy(&res_host, res_dev, sizeof(float), cudaMemcpyDeviceToHost);)"}
{"predict": "(2, MPI, MPI_Comm_size(MPI_COMM_WORLD, &size);); (2, MPI, MPI_Comm_rank(MPI_COMM_WORLD, &rank);)", "label": "(2, MPI, MPI_Comm_size(MPI_COMM_WORLD, &size);); (2, MPI, MPI_Comm_rank(MPI_COMM_WORLD, &rank);)"}
{"predict": "(13, TBB, return tbb::parallel_deterministic_reduce(tbb::blocked_range<size_t>(UL(0), my_moves.size()), accum, std::plus<Gain>());)", "label": "(14, TBB, return tbb::parallel_reduce(range, 0, accum, std::plus<>());); (3, TBB, auto range = tbb::blocked_range<size_t>(UL(0), end);)"}
{"predict": "(12, CUDA, cudaDeviceSynchronize();)", "label": "(12, CUDA, cudaDeviceSynchronize();)"}
{"predict": "(15, MPI, MPI_Finalize();); (1, MPI, MPI_Init(&argc,&argv);)", "label": "(15, MPI, MPI_Finalize();); (1, MPI, MPI_Init(&argc,&argv);)"}
{"predict": "(4, OpenMP, #pragma omp parallel for)", "label": "(4, OpenMP, #pragma omp parallel for)"}
{"predict": "(9, CUDA, checkCudaErrors(cudaFuncGetAttributes(&attr,ptr));); (6, CUDA, checkCudaErrors(cudaOccupancyMaxActiveBlocksPerMultiprocessor(&qblocksize,ptr,0,0));)", "label": "(9, CUDA, cudaFuncGetAttributes(&attr,(void*)ptr);); (14, CUDA, fcuda::Check_CudaErroorFun(\"Error collecting kernel information.\");); (5, CUDA, cudaOccupancyMaxPotentialBlockSize(&mingridsize,&qblocksize,(void*)ptr,0,0);)"}
{"predict": "(4, CUDA, __shared__ float Bs[block_size][block_size];); (2, CUDA, __shared__ float As[block_size][block_size];)", "label": "(4, CUDA, __shared__ float Bs[block_size][block_size];); (2, CUDA, __shared__ float As[block_size][block_size];)"}
{"predict": "(11, MPI, MPI_Type_get_true_extent(item, &lb, &extent);)", "label": "(11, MPI, MPI_Type_get_extent(item, &lb, &extent);)"}
{"predict": "(42, MPI, MPI_T_finalize();); (17, MPI, MPI_T_init_thread(required, &provided);)", "label": "(42, MPI, MPI_T_finalize();); (17, MPI, MPI_T_init_thread(required, &provided);)"}
{"predict": "(5, CUDA, __shared__ float reduce_smem[NUM_WARPS];)", "label": "(5, CUDA, __shared__ float reduce_smem[NUM_WARPS];)"}
{"predict": "(2, TBB, typedef tbb::cache< tbb::cache_policy_lru, int > cache_type;)", "label": "(10, TBB, static const size_t number_of_threads = 4 * tbb::task_scheduler_init::default_num_threads();)"}
{"predict": "(5, CUDA, __shared__ float reduce_smem[NUM_WARPS];)", "label": "(5, CUDA, __shared__ float reduce_smem[NUM_WARPS];)"}
{"predict": "(4, CUDA, const T** input_ptrs = GetCudaDeviceArrayOnDevice(&input_ptr_data);)", "label": "(4, CUDA, const T** input_ptrs = GetCudaDeviceArrayOnDevice(&input_ptr_data);)"}
{"predict": "(3, TBB, ValueType r1 = tbb::parallel_reduce( m_range, I, Sum(), partitioner );)", "label": "(3, TBB, ValueType r1 = tbb::parallel_reduce( m_range, I, Accumulator(), Sum(), partitioner );)"}
{"predict": "(22, MPI, MPI_Finalize();); (1, MPI, MPI_Init(&argc,&argv);)", "label": "(22, MPI, MPI_Finalize();); (1, MPI, MPI_Init(&argc,&argv);)"}
{"predict": "(38, CUDA, CUDA_CHECK(cudaStreamSynchronize(stream));); (40, CUDA, CUDA_CHECK(cudaFree(d_data));)", "label": "(38, CUDA, CUDA_CHECK(cudaStreamSynchronize(stream));); (40, CUDA, CUDA_CHECK(cudaFree(d_data));)"}
{"predict": "(12, OpenMP, #pragma omp target)", "label": "(12, OpenMP, #pragma omp target)"}
{"predict": "(10, MPI, MPI_Abort(MPI_COMM_WORLD, EXIT_FAILURE);)", "label": "(10, MPI, MPI_Abort(MPI_COMM_WORLD, EXIT_FAILURE);)"}
{"predict": "(3, OpenMP, #pragma omp target data map(present: i)); (6, OpenMP, #pragma omp target data map(present: i) map(from: i))", "label": "(3, OpenMP, #pragma omp target enter data map(alloc:i)); (6, OpenMP, #pragma omp target data map(present, alloc: i)); (7, OpenMP, #pragma omp target exit data map(delete:i))"}
{"predict": "(41, OpenCL, TEST_OCL_CHECK(clReleaseCommandQueue(ocl_queue));)", "label": "(27, OpenCL, TEST_OCL_CHECK(clReleaseCommandQueue(ocl_queue));)"}
{"predict": "(4, OpenMP, #pragma omp target enter data map(to:a[:n])); (8, OpenMP, #pragma omp target exit data map(from:a[:n]))", "label": "(5, OpenMP, #pragma omp target teams distribute parallel for)"}
{"predict": "(9, SYCL, sycl::device device;)", "label": "(9, SYCL, sycl::device device;)"}
{"predict": "(36, CUDA, CUDA_CHECK(cudaStreamSynchronize(stream));); (38, CUDA, CUDA_CHECK(cudaFree(d_data));)", "label": "(36, CUDA, CUDA_CHECK(cudaStreamSynchronize(stream));); (38, CUDA, CUDA_CHECK(cudaFree(d_data));)"}
{"predict": "(14, CUDA, cuda::CUDABlas *blas = new cuda::CUDABlas(cuda_executor);)", "label": "(14, CUDA, cuda::CUDABlas *blas = new cuda::CUDABlas(cuda_executor);)"}
{"predict": "(13, CUDA, qmc_cuda::cuda_check(cudaDeviceSynchronize());); (11, CUDA, qmc_cuda::cuda_check(cudaGetLastError());)", "label": "(13, CUDA, qmc_cuda::cuda_check(cudaDeviceSynchronize());); (11, CUDA, qmc_cuda::cuda_check(cudaGetLastError());)"}
{"predict": "(11, MPI, MPI_Error_string(code, msg, &resultLen);); (12, MPI, MPI_Abort(MPI_COMM_WORLD, code);); (8, MPI, MPI_Error_class(code, &class);)", "label": "(11, MPI, MPI_Error_string(code, msg, &resultLen);); (12, MPI, MPI_Abort(MPI_COMM_WORLD, code);); (8, MPI, MPI_Error_class(code, &class);)"}
{"predict": "(14, MPI, MPI_Finalize();); (1, MPI, MPI_Init(&argc,&argv);)", "label": "(14, MPI, MPI_Finalize();); (1, MPI, MPI_Init(&argc,&argv);)"}
{"predict": "(12, CUDA, A[blockIdx.z * stride + i * lda + i] = thrust::complex<T>(0.0, 0.0);); (7, CUDA, A[blockIdx.z * stride + i * lda + i] = thrust::complex<T>(1.0, 0.0);)", "label": "(8, CUDA, A[blockIdx.z * stride + i * lda + i] = thrust::complex<T>(1.0, 0.0);); (11, CUDA, A[blockIdx.z * stride + j * lda + i] = thrust::complex<T>(0.0, 0.0);)"}
{"predict": "(11, TBB, tbb::task_scheduler_init init(nthread);)", "label": "(11, TBB, tbb::task_scheduler_init init(nthread);)"}
{"predict": "(7, TBB, tbb::blocked_range<RangeType> range2(range,tbb::split());)", "label": "(7, TBB, RangeType range2( range, tbb::split() );)"}
{"predict": "(20, MPI, MPI_Allreduce( & tmp , & result , 1 , MPI_DOUBLE , MPI_SUM , MPI_COMM_WORLD );)", "label": "(20, MPI, MPI_Allreduce( & tmp , & result , 1 , MPI_DOUBLE , MPI_SUM , MPI_COMM_WORLD );)"}
{"predict": "(3, CUDA, __shared__ float local[threads];)", "label": "(3, CUDA, __shared__ float local[threads];)"}
{"predict": "(2, MPI, MPI_Init(&argc, &argv);); (29, MPI, MPI_Finalize();)", "label": "(8, MPI, MPI_Init(&argc, &argv);); (28, MPI, MPI_Finalize();)"}
{"predict": "(20, CUDA, cudaStream_t stream = at::cuda::getCurrentCUDAStream();)", "label": "(20, CUDA, cudaStream_t stream = at::cuda::getCurrentCUDAStream();)"}
{"predict": "(14, MPI, MPI_Abort(MPI_COMM_WORLD, 127);)", "label": "(14, MPI, MPI_Abort(MPI_COMM_WORLD, 127);)"}
{"predict": "(34, OpenCL, TEST_OCL_CHECK(clReleaseCommandQueue(interop_ocl_queue));)", "label": "(34, OpenCL, TEST_OCL_CHECK(clReleaseCommandQueue(interop_ocl_queue));)"}
{"predict": "(18, MPI, *ierr = MPI_Info_delete( (MPI_Info)(*v1), p2 );)", "label": "(18, MPI, *ierr = MPI_Info_delete( (MPI_Info)(*v1), p2 );)"}
{"predict": "(2, TBB, tbb::tick_count t0 = tbb::tick_count::now();); (11, TBB, tbb::tick_count t1 = tbb::tick_count::now();)", "label": "(2, TBB, tbb::tick_count t0 = tbb::tick_count::now();); (11, TBB, tbb::tick_count t1 = tbb::tick_count::now();)"}
{"predict": "(12, CUDA, A_[j] = static_cast<thrust::complex<T1>>(B_[j]);)", "label": "(12, CUDA, A_[j] = static_cast<thrust::complex<T1>>(B_[j]);)"}
{"predict": "(16, MPI, MPI_Comm_set_errhandler(MPI_COMM_WORLD, MPI_ERRORS_RETURN);)", "label": "(16, MPI, MPI_Comm_set_errhandler(MPI_COMM_WORLD, MPI_ERRORS_RETURN);)"}
{"predict": "(8, CUDA, cudaStreamSynchronize(LU_v1->A_gpu.cuStreams[0]);)", "label": "(8, CUDA, cudaStreamSynchronize(LU_v1->A_gpu.cuStreams[0]);)"}
{"predict": "(31, MPI, MPI_Comm_rank(MPI_COMM_WORLD, &rank);)", "label": "(31, MPI, MPI_Comm_rank(MPI_COMM_WORLD, &rank);)"}
{"predict": "(5, CUDA, __shared__ float reduce_smem[NUM_WARPS];)", "label": "(5, CUDA, __shared__ float reduce_smem[NUM_WARPS];)"}
{"predict": "(4, OpenMP, #pragma omp atomic seq_cst); (8, OpenMP, #pragma omp atomic seq_cst seq_cst); (10, OpenMP, #pragma omp atomic update seq_cst)", "label": "(4, OpenMP, #pragma omp atomic seq_cst); (8, OpenMP, #pragma omp atomic seq_cst seq_cst); (10, OpenMP, #pragma omp atomic update seq_cst)"}
{"predict": "(12, CUDA, img[idx] = cudaAlphaBlend(img[idx], color);)", "label": "(12, CUDA, img[idx] = cudaAlphaBlend(img[idx], color);)"}
{"predict": "(5, CUDA, __shared__ float reduce_smem[NUM_WARPS];)", "label": "(5, CUDA, __shared__ float reduce_smem[NUM_WARPS];)"}
{"predict": "(8, OpenCL, retVal = clEnqueueMemcpyINTEL(commandQueues[0][0].get(), true, deviceMemAlloc, buffer.data(), bufferSize, 0, nullptr, nullptr);); (16, OpenCL, retVal = clEnqueueMemcpyINTEL(commandQueues[0][0].get(), true, hostMemAlloc, deviceMemAlloc, bufferSize, 0, nullptr, nullptr);)", "label": "(8, OpenCL, retVal = clEnqueueMemcpyINTEL(commandQueues[0][0].get(), true, deviceMemAlloc, buffer.data(), bufferSize, 0, nullptr, nullptr);); (16, OpenCL, retVal = clEnqueueMemcpyINTEL(commandQueues[0][0].get(), true, hostMemAlloc, deviceMemAlloc, bufferSize, 0, nullptr, nullptr);)"}
{"predict": "(2, CUDA, extern __shared__ char smem[];)", "label": "(2, CUDA, extern __shared__ char smem[];)"}
{"predict": "(8, CUDA, sim->CUDAConfig().device_id = device;)", "label": "(8, CUDA, sim->CUDAConfig().device_id = device;)"}
{"predict": "(13, CUDA, PyObject* shape = PyCudaImage_GetShape(self, closure);)", "label": "(13, CUDA, PyObject* shape = PyCudaImage_GetShape(self, closure);)"}
{"predict": "(2, MPI, MPIDataCommunicator mpi_world_communicator(MPI_COMM_WORLD);)", "label": "(2, MPI, MPIDataCommunicator mpi_world_communicator(MPI_COMM_WORLD);)"}
{"predict": "(36, CUDA, CUDA_CHECK(cudaStreamSynchronize(stream));); (38, CUDA, CUDA_CHECK(cudaFree(d_data));)", "label": "(36, CUDA, CUDA_CHECK(cudaStreamSynchronize(stream));); (38, CUDA, CUDA_CHECK(cudaFree(d_data));)"}
{"predict": "(2, CUDA, __shared__ int sharedMemory [BLOCK_SIZE] [BLOCK_SIZE + 1];)", "label": "(2, CUDA, __shared__ int sharedMemory [BLOCK_SIZE] [BLOCK_SIZE + 1];)"}
{"predict": "(4, OpenMP, #pragma omp parallel for)", "label": "(4, OpenMP, #pragma omp parallel for)"}
{"predict": "(14, OpenMP, #pragma omp teams default(none), private(argc,b) num_teams(f) firstprivate(argv) reduction(| : c, d) reduction(* : e) thread_limit(f+g)); (6, OpenMP, #pragma omp target); (2, OpenMP, #pragma omp threadprivate(a)); (5, OpenMP, #pragma omp teams)", "label": "(14, OpenMP, #pragma omp teams default(none), private(argc,b) num_teams(f) firstprivate(argv) reduction(| : c, d) reduction(* : e) thread_limit(f+g)); (6, OpenMP, #pragma omp target); (2, OpenMP, #pragma omp threadprivate(a)); (5, OpenMP, #pragma omp teams)"}
{"predict": "(341, CUDA, __shared__ int cur_send_num;); (339, CUDA, __shared__ int recv_num, finish_num;)", "label": "(341, CUDA, __shared__ int cur_send_num;); (339, CUDA, __shared__ int recv_num, finish_num;)"}
{"predict": "(23, OpenCL, clReleaseEvent(event);)", "label": "(23, OpenCL, clReleaseEvent(event);)"}
{"predict": "(1, SYCL, EasyCL *cl = EasyCL::createForFirstGpuOtherwiseCpu();)", "label": "(1, SYCL, EasyCL *cl = EasyCL::createForFirstGpuOtherwiseCpu();)"}
